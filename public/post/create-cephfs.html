<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    
    <title>第四篇：创建cephfs服务 | zuoyang&#39;s blog</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="基于上一篇，我们搭建好了一个健康的ceph集群：  3个mon节点组成的mon集群 9个osd节点组成的osd集群 3个mgr节点(ceph luminous版本才有的) 3个mds服务(cephfs使用)  123456789101112131415[root@ceph-1 ceph]# ceph -s  cluster:    id:     c165f9d0-88df-48a7-8cc5-1">
<meta name="keywords" content="ceph,cephfs">
<meta property="og:type" content="article">
<meta property="og:title" content="第四篇：创建cephfs服务">
<meta property="og:url" content="https://www.zuoyangblog.com/post/create-cephfs.html">
<meta property="og:site_name" content="zuoyang&#39;s blog">
<meta property="og:description" content="基于上一篇，我们搭建好了一个健康的ceph集群：  3个mon节点组成的mon集群 9个osd节点组成的osd集群 3个mgr节点(ceph luminous版本才有的) 3个mds服务(cephfs使用)  123456789101112131415[root@ceph-1 ceph]# ceph -s  cluster:    id:     c165f9d0-88df-48a7-8cc5-1">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://www.zuoyangblog.com/post/create-cephfs/cephfs.jpg">
<meta property="og:image" content="https://www.zuoyangblog.com/post/create-cephfs/ceph_archite.jpg">
<meta property="og:updated_time" content="2018-11-23T08:06:09.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第四篇：创建cephfs服务">
<meta name="twitter:description" content="基于上一篇，我们搭建好了一个健康的ceph集群：  3个mon节点组成的mon集群 9个osd节点组成的osd集群 3个mgr节点(ceph luminous版本才有的) 3个mds服务(cephfs使用)  123456789101112131415[root@ceph-1 ceph]# ceph -s  cluster:    id:     c165f9d0-88df-48a7-8cc5-1">
<meta name="twitter:image" content="https://www.zuoyangblog.com/post/create-cephfs/cephfs.jpg">
    

    

    
        <link rel="icon" href="../css/images/horse.jpg">
    

    <link rel="stylesheet" href="../libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="../libs/open-sans/styles.css">
    <link rel="stylesheet" href="../libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="../css/style.css">

    <script src="../libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="../libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="../libs/justified-gallery/justifiedGallery.min.css">
    
    
        <script type="text/javascript">
(function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-129296219-1', 'auto');
ga('send', 'pageview');

</script>
    
    
    


</head>
</html>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="../index.html" id="logo">
                <i class="logo"></i>
                <span class="site-title">zuoyang&#39;s blog</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="../.">Home</a>
                
                    <a class="main-nav-link" href="../archives">Archives</a>
                
                    <a class="main-nav-link" href="../categories">Categories</a>
                
                    <a class="main-nav-link" href="../tags">Tags</a>
                
                    <a class="main-nav-link" href="../about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="../css/images/profile_pic.jpg">
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '../content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="../js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="../.">Home</a></td>
                
                    <td><a class="main-nav-link" href="../archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="../categories">Categories</a></td>
                
                    <td><a class="main-nav-link" href="../tags">Tags</a></td>
                
                    <td><a class="main-nav-link" href="../about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search">
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <script type='text/javascript'>
                $('body').append("<style type='text/css'>@media screen and (min-width: 1200px) { #main {margin: auto; width: 70%; display: block; float:none;}}</style>");
                </script>
                <script type='text/javascript'>
                document.querySelector('style').textContent += "@media screen and (max-width: 1199px) and (min-width: 800px) { #main {margin: auto; width: 70%; display: block; float:none;}}"
                </script>
            
            <section id="main"><article id="post-create-cephfs" class="article article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name" style="color: #009688;font-size:1.5em;">
            第四篇：创建cephfs服务
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="../categories/ceph/">ceph</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="../tags/ceph/">ceph</a>, <a class="tag-link" href="../tags/cephfs/">cephfs</a>
    </div>

                        
                            <i class="fa fa-eye"></i> <span id="busuanzi_value_page_pv"></span>次
                        
                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">Catalogue</strong>
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">1.</span> <span class="toc-text">cephFS简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">2.</span> <span class="toc-text">新建ceph client虚拟机</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.1.</span> <span class="toc-text">修改ifcfg-enp0s3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.2.</span> <span class="toc-text">修改ifcfg-enp0s8</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.3.</span> <span class="toc-text">重启网卡并检查联网状态：</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.4.</span> <span class="toc-text">修改主机名hostname:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.5.</span> <span class="toc-text">重启，通过本机终端登录</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.6.</span> <span class="toc-text">修改yum源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.7.</span> <span class="toc-text">配置ceph源</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">2.8.</span> <span class="toc-text">安装软件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">3.</span> <span class="toc-text">创建cephFS</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">3.1.</span> <span class="toc-text">创建cephfs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">3.2.</span> <span class="toc-text">挂载cephfs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">3.2.1.</span> <span class="toc-text">内核驱动 (with kernel)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">3.2.2.</span> <span class="toc-text">使用fuse (with fuse)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol>
                </div>
            
        
        
            <p>基于<a href="https://www.zuoyangblog.com/post/28a4bfb3.html">上一篇</a>，我们搭建好了一个健康的ceph集群：</p>
<ul>
<li>3个mon节点组成的mon集群</li>
<li>9个osd节点组成的osd集群</li>
<li>3个mgr节点(ceph luminous版本才有的)</li>
<li>3个mds服务(cephfs使用)</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-1 ceph]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     c165f9d0-88df-48a7-8cc5-11da82f99c93</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3</span><br><span class="line">    mgr: ceph-1(active), standbys: admin, ceph-2, ceph-3</span><br><span class="line">    osd: 9 osds: 9 up, 9 in</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   0 pools, 0 pgs</span><br><span class="line">    objects: 0 objects, 0B</span><br><span class="line">    usage:   965MiB used, 18.0TiB / 18.0TiB avail</span><br><span class="line">    pgs:</span><br></pre></td></tr></table></figure>
<p>本篇主要讲如何基于ceph集群搭建cephfs服务。</p>
<h1><span id="cephfs简介">cephFS简介</span></h1><p>The <a href="http://docs.ceph.com/docs/mimic/glossary/#term-ceph-filesystem" target="_blank" rel="noopener">Ceph Filesystem</a> (Ceph FS) is a POSIX-compliant filesystem that uses a Ceph Storage Cluster to store its data. </p>
<img src="/post/create-cephfs/cephfs.jpg">
<p>Ceph文件系统（CephFS）提供符合POSIX标准的文件系统作为服务，该服务在基于对象的Ceph存储集群之上。 CephFS文件被映射到Ceph存储在Ceph存储集群中的对象。 Ceph客户端有两种挂载cephfs的方式：基于内核和FUSE.下图为cephfs的结构图：</p>
<img src="/post/create-cephfs/ceph_archite.jpg">
<p>Ceph文件系统服务包括与Ceph存储集群一起部署的Ceph元数据服务器（MDS）。 MDS存储了文件系统里的所有元数据（目录，文件所有权，访问模式等）。 MDS（ceph-mds的守护进程）将一些简单的文件系统操作（例如列出目录或更改目录（ls，cd）等）与Ceph OSD守护进程隔离，这样可以减少对OSD进程造成不必要的负担。 因此，将元数据与数据分离意味着Ceph文件系统可以提供高性能服务，而不会对Ceph存储集群造成负担。</p>
<ul>
<li>MDS：存储metadata(元数据)</li>
<li>OSD：存储file data(数据)</li>
</ul>
<p>ceph-mds可以作为单个进程运行，也可以分发到多个物理机器，以实现高可用性或可伸缩性。</p>
<ul>
<li>高可用性：集群中处于standby状态的ceph-mds进程随时可以取代失败的active状态的ceph-mds，当active状态的ceph-mds进程失败时，ceph-mon很容易就可以把standby状态的mds转换成active状态，从而维持集群的可用性</li>
<li>可扩展性：集群中可以有多个active状态的ceph-mds进程，它们会将目录树拆分为子树（以及单个繁忙目录的分片），从而有效地平衡所有活动服务器之间的负载。</li>
</ul>
<h1><span id="新建ceph-client虚拟机">新建ceph client虚拟机</span></h1><p>根据<a href="https://www.zuoyangblog.com/post/ad293d8.html">第二篇</a>的方法，新建一个虚拟机，我们命名为ceph-client.</p>
<p>安装好之后配置相应的网络，具体方法详见<a href="https://www.zuoyangblog.com/post/ad293d8.html">这里</a></p>
<h2><span id="修改ifcfg-enp0s3">修改ifcfg-enp0s3</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-enp0s3</span><br></pre></td></tr></table></figure>
<p>将最后一行的<code>ONBOOT=no</code>改为<code>ONBOOT=yes</code>,添加IPADDR，NETMASK，这个是<code>网卡1</code>，用于给虚拟机上网。</p>
<h2><span id="修改ifcfg-enp0s8">修改ifcfg-enp0s8</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysconfig/network-scripts/ifcfg-enp0s8</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.56.200</span><br><span class="line">NETMASK=255.255.255.0</span><br></pre></td></tr></table></figure>
<h2><span id="重启网卡并检查联网状态">重启网卡并检查联网状态：</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure>
<h2><span id="修改主机名hostname">修改主机名<code>hostname</code>:</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo ceph-client &gt; /etc/hostname</span><br></pre></td></tr></table></figure>
<h2><span id="重启通过本机终端登录">重启，通过本机终端登录</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh root@192.168.56.200</span><br></pre></td></tr></table></figure>
<h2><span id="修改yum源">修改yum源</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum clean all</span><br><span class="line">curl http://mirrors.aliyun.com/repo/Centos-7.repo &gt;/etc/yum.repos.d/CentOS-Base.repo</span><br><span class="line">curl http://mirrors.aliyun.com/repo/epel-7.repo &gt;/etc/yum.repos.d/epel.repo </span><br><span class="line">sed -i '/aliyuncs/d' /etc/yum.repos.d/CentOS-Base.repo</span><br><span class="line">sed -i '/aliyuncs/d' /etc/yum.repos.d/epel.repo</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>
<h2><span id="配置ceph源">配置ceph源</span></h2><p>在<code>/etc/yum.repos.d/</code>目录下新增一个ceph源文件<code>ceph.repo</code>,并写入下面内容：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/yum.repos.d/ceph.repo</span><br><span class="line"><span class="meta">#</span><span class="bash">写入以下内容</span></span><br><span class="line">[ceph]</span><br><span class="line">name=ceph</span><br><span class="line">baseurl=http://mirrors.aliyun.com/ceph/rpm-luminous/el7/x86_64/</span><br><span class="line">gpgcheck=0</span><br><span class="line">[ceph-noarch]</span><br><span class="line">name=cephnoarch</span><br><span class="line">baseurl=http://mirrors.aliyun.com/ceph/rpm-luminous/el7/noarch/</span><br><span class="line">gpgcheck=0</span><br><span class="line">[ceph-source]</span><br><span class="line">name=ceph-source</span><br><span class="line">baseurl=http://mirrors.aliyun.com/ceph/rpm-luminous/el7/SRPMS/</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure>
<h2><span id="安装软件">安装软件</span></h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum clean all &amp;&amp; yum makecache</span><br><span class="line">yum -y install yum-plugin-priorities </span><br><span class="line">yum -y install openssh-server</span><br></pre></td></tr></table></figure>
<h1><span id="创建cephfs">创建cephFS</span></h1><p>登录mon集群的那三台机器中的一台即可，我这里登录ceph-1</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh root@192.168.56.101</span><br></pre></td></tr></table></figure>
<h2><span id="创建cephfs">创建cephfs</span></h2><p>creatring pools</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-1 ceph]# ceph osd pool create cephfs_data 64</span><br><span class="line">pool 'cephfs_data' created</span><br><span class="line">[root@ceph-1 ceph]# ceph osd pool create cephfs_metadata 64</span><br><span class="line">pool 'cephfs_metadata' created</span><br></pre></td></tr></table></figure>
<p>creating a filesystem</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-1 ceph]# ceph fs new cephfs cephfs_metadata cephfs_data</span><br><span class="line">new fs with metadata pool 2 and data pool 1</span><br><span class="line">[root@ceph-1 ceph]# ceph fs ls</span><br><span class="line">name: cephfs, metadata pool: cephfs_metadata, data pools: [cephfs_data ]</span><br></pre></td></tr></table></figure>
<p>一旦文件系统创建好之后，mds的状态就会发生变化，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-1 ceph]# ceph mds stat</span><br><span class="line">cephfs-1/1/1 up  &#123;0=ceph-2=up:active&#125;, 2 up:standby</span><br></pre></td></tr></table></figure>
<p>再看看集群状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-1 ceph]# ceph -s</span><br><span class="line">  cluster:</span><br><span class="line">    id:     c165f9d0-88df-48a7-8cc5-11da82f99c93</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"></span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3</span><br><span class="line">    mgr: ceph-1(active), standbys: admin, ceph-2, ceph-3</span><br><span class="line">    mds: cephfs-1/1/1 up  &#123;0=ceph-2=up:active&#125;, 2 up:standby</span><br><span class="line">    osd: 9 osds: 9 up, 9 in</span><br><span class="line"></span><br><span class="line">  data:</span><br><span class="line">    pools:   2 pools, 128 pgs</span><br><span class="line">    objects: 21 objects, 3.14KiB</span><br><span class="line">    usage:   967MiB used, 18.0TiB / 18.0TiB avail</span><br><span class="line">    pgs:     128 active+clean</span><br></pre></td></tr></table></figure>
<ul>
<li>mds进入active状态</li>
<li>生成了两个pool，128个pg</li>
</ul>
<h2><span id="挂载cephfs">挂载cephfs</span></h2><p>cephfs支持两种方式挂载：</p>
<ul>
<li>内核驱动</li>
<li>使用fuse</li>
</ul>
<p>这是官网给出的两种挂载方式的对比：</p>
<p>The <strong>FUSE client</strong> is the most accessible and the easiest to upgrade to the version of Ceph used by the storage cluster, while the <strong>kernel client</strong> will often give better performance.</p>
<p>The clients do not always provide equivalent functionality, for example the <strong>fuse client</strong> supports client-enforced quotas while the <strong>kernel client</strong> does not.</p>
<h3><span id="内核驱动-with-kernel">内核驱动 (with kernel)</span></h3><p>ceph一个集群只支持创建一个cephfs,所以只要创建一次cephfs之后，就可以在客户端机器上创建目录并挂载到集群：</p>
<p>在客户端机器上进行如下操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-client ~]# mkdir -p /mycephfs</span><br><span class="line">[root@ceph-client ~]# mount -t ceph 192.168.56.101,192.168.56.102,192.168.56.103:6789:/ /mycephfs</span><br></pre></td></tr></table></figure>
<p>查看挂载情况：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-client ~]# df -h</span><br><span class="line">文件系统                                             容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root                               50G  1.6G   49G    4% /</span><br><span class="line">devtmpfs                                             485M     0  485M    0% /dev</span><br><span class="line">tmpfs                                                496M     0  496M    0% /dev/shm</span><br><span class="line">tmpfs                                                496M  6.8M  490M    2% /run</span><br><span class="line">tmpfs                                                496M     0  496M    0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                                           1014M  129M  886M   13% /boot</span><br><span class="line">/dev/mapper/centos-home                              347G   35M  347G    1% /home</span><br><span class="line">tmpfs                                                100M     0  100M    0% /run/user/0</span><br><span class="line">192.168.56.101,192.168.56.102,192.168.56.103:6789:/  5.4T     0  5.4T    0% /mycephfs</span><br></pre></td></tr></table></figure>
<p>最后一行可以看到挂载成功。</p>
<h3><span id="使用fuse-with-fuse">使用fuse (with fuse)</span></h3><p>使用fuse方式进行挂载，需要安装ceph-fuse工具，</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-client ~]# yum install ceph-fuse</span><br><span class="line"> ........</span><br><span class="line">已安装:</span><br><span class="line">  ceph-fuse.x86_64 2:12.2.9-0.el7</span><br><span class="line"></span><br><span class="line">作为依赖被安装:</span><br><span class="line">  fuse-libs.x86_64 0:2.9.2-10.el7    gperftools-libs.x86_64 0:2.6.1-1.el7    libibverbs.x86_64 0:15-7.el7_5    pciutils.x86_64 0:3.5.1-3.el7</span><br><span class="line">  rdma-core.x86_64 0:15-7.el7_5</span><br><span class="line"></span><br><span class="line">完毕！</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-client ~]# ceph-fuse -v</span><br><span class="line">ceph version 12.2.9 (9e300932ef8a8916fb3fda78c58691a6ab0f4217) luminous (stable)</span><br></pre></td></tr></table></figure>
<p>ceph-fuse安装完成。</p>
<p>挂载cephfs</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-client ~]# mkdir /fusefs</span><br><span class="line">[root@ceph-client ~]# ceph-fuse -m 192.168.56.101:6789 /fusefs</span><br><span class="line">ceph-fuse[10854]: starting ceph client</span><br><span class="line">ceph-fuse[10854]: starting fuse</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@ceph-client ~]# df -h</span><br><span class="line">文件系统                                             容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/mapper/centos-root                               50G  1.6G   49G    4% /</span><br><span class="line">devtmpfs                                             485M     0  485M    0% /dev</span><br><span class="line">tmpfs                                                496M     0  496M    0% /dev/shm</span><br><span class="line">tmpfs                                                496M  6.8M  490M    2% /run</span><br><span class="line">tmpfs                                                496M     0  496M    0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1                                           1014M  129M  886M   13% /boot</span><br><span class="line">/dev/mapper/centos-home                              347G   35M  347G    1% /home</span><br><span class="line">tmpfs                                                100M     0  100M    0% /run/user/0</span><br><span class="line">192.168.56.101,192.168.56.102,192.168.56.103:6789:/  5.4T     0  5.4T    0% /mycephfs</span><br><span class="line">ceph-fuse                                            5.4T     0  5.4T    0% /fusefs</span><br></pre></td></tr></table></figure>
<p>查看最后一行，说明挂载成功。</p>
<h1><span id="总结">总结</span></h1><p>本篇主要介绍了cephfs的架构以及在ceph集群上挂载cephfs的流程。</p>

            </div>
        
        </div>
        
    
    
        
<nav id="article-nav">
    
    
        <a href="manual-deploy-ceph.html" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">第三篇：手动部署Ceph集群</div>
        </a>
    
</nav>


    
</article>


    
    <section id="comments">
    
        <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<div class="gitalk">
    <div id="gitalk-container"></div>
    <script type="text/javascript">
        const gitalk = new Gitalk({
            clientID: '6b346f4de8336f10e022',
            clientSecret: '706a95586b24195c087762bf6f2d49f0bf78735d',
            repo: 'cheneyoung.github.io',
            owner: 'cheneyoung',
            admin: ['cheneyoung'],
            id: "https://www.zuoyangblog.com/post/create-cephfs.html".substr(19,50),      // Ensure uniqueness and length less than 50
            distractionFreeMode: false  // Facebook-like distraction free mode
        })

        gitalk.render('gitalk-container')
    </script>
</div>
    
    </section>


</section>
            
            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2018 zuoyang<br>
               <!-- 首先引入统计用的js，然后编写相应的统计代码 -->
               <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
               访问量<span id="busuanzi_value_site_pv"></span>次  <i class="fa fa-user-md"></i>  访客数<span id="busuanzi_value_site_uv"></span>人
        </div>
    </div>
</footer>

        
    <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<div class="gitalk">
    <div id="gitalk-container"></div>
    <script type="text/javascript">
        const gitalk = new Gitalk({
            clientID: '6b346f4de8336f10e022',
            clientSecret: '706a95586b24195c087762bf6f2d49f0bf78735d',
            repo: 'cheneyoung.github.io',
            owner: 'cheneyoung',
            admin: ['cheneyoung'],
            id: "https://www.zuoyangblog.com/post/create-cephfs.html".substr(19,50),      // Ensure uniqueness and length less than 50
            distractionFreeMode: false  // Facebook-like distraction free mode
        })

        gitalk.render('gitalk-container')
    </script>
</div>



    
        <script src="../libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="../libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="../libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="../libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="../libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="../libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="../libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="../libs/lightgallery/js/lg-share.min.js"></script>
        <script src="../libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="../libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    



<!-- Custom Scripts -->
<script src="../js/main.js"></script>

    </div>
</body>
</html>