{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/icarus/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/insight.js","path":"js/insight.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/js/main.js","path":"js/main.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/avatar.png","path":"css/images/avatar.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/logo.png","path":"css/images/logo.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/thumb-default-small.png","path":"css/images/thumb-default-small.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/whale.png","path":"css/images/whale.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/justified-gallery/jquery.justifiedGallery.min.js","path":"libs/justified-gallery/jquery.justifiedGallery.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/justified-gallery/justifiedGallery.min.css","path":"libs/justified-gallery/justifiedGallery.min.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/styles.css","path":"libs/open-sans/styles.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/source-code-pro/styles.css","path":"libs/source-code-pro/styles.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/favicon.ico","path":"css/images/favicon.ico","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/horse.jpg","path":"css/images/horse.jpg","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/css/font-awesome.css","path":"libs/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/css/font-awesome.min.css","path":"libs/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-fb-comment-box.css","path":"libs/lightgallery/css/lg-fb-comment-box.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-fb-comment-box.css.map","path":"libs/lightgallery/css/lg-fb-comment-box.css.map","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-fb-comment-box.min.css","path":"libs/lightgallery/css/lg-fb-comment-box.min.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-transitions.css","path":"libs/lightgallery/css/lg-transitions.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-transitions.css.map","path":"libs/lightgallery/css/lg-transitions.css.map","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lightgallery.css","path":"libs/lightgallery/css/lightgallery.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-transitions.min.css","path":"libs/lightgallery/css/lg-transitions.min.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lightgallery.css.map","path":"libs/lightgallery/css/lightgallery.css.map","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/css/lightgallery.min.css","path":"libs/lightgallery/css/lightgallery.min.css","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.eot","path":"libs/lightgallery/fonts/lg.eot","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.svg","path":"libs/lightgallery/fonts/lg.svg","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.ttf","path":"libs/lightgallery/fonts/lg.ttf","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.woff","path":"libs/lightgallery/fonts/lg.woff","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/img/loading.gif","path":"libs/lightgallery/img/loading.gif","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/img/vimeo-play.png","path":"libs/lightgallery/img/vimeo-play.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/img/video-play.png","path":"libs/lightgallery/img/video-play.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/img/youtube-play.png","path":"libs/lightgallery/img/youtube-play.png","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-autoplay.js","path":"libs/lightgallery/js/lg-autoplay.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-autoplay.min.js","path":"libs/lightgallery/js/lg-autoplay.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-fullscreen.js","path":"libs/lightgallery/js/lg-fullscreen.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-fullscreen.min.js","path":"libs/lightgallery/js/lg-fullscreen.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-hash.js","path":"libs/lightgallery/js/lg-hash.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-hash.min.js","path":"libs/lightgallery/js/lg-hash.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-pager.js","path":"libs/lightgallery/js/lg-pager.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-pager.min.js","path":"libs/lightgallery/js/lg-pager.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-share.js","path":"libs/lightgallery/js/lg-share.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-share.min.js","path":"libs/lightgallery/js/lg-share.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-thumbnail.js","path":"libs/lightgallery/js/lg-thumbnail.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-thumbnail.min.js","path":"libs/lightgallery/js/lg-thumbnail.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-video.js","path":"libs/lightgallery/js/lg-video.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-video.min.js","path":"libs/lightgallery/js/lg-video.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-zoom.min.js","path":"libs/lightgallery/js/lg-zoom.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-zoom.js","path":"libs/lightgallery/js/lg-zoom.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lightgallery.js","path":"libs/lightgallery/js/lightgallery.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","path":"libs/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/lightgallery/js/lightgallery.min.js","path":"libs/lightgallery/js/lightgallery.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","path":"libs/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","path":"libs/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","path":"libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","path":"libs/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","path":"libs/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","path":"libs/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","path":"libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","path":"libs/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","path":"libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","path":"libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.eot","path":"libs/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.woff","path":"libs/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.woff2","path":"libs/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/jquery/2.1.3/jquery.min.js","path":"libs/jquery/2.1.3/jquery.min.js","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.ttf","path":"libs/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/icarus/source/css/images/profile_pic.jpg","path":"css/images/profile_pic.jpg","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/fonts/FontAwesome.otf","path":"libs/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.svg","path":"libs/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"ad3dc80f4dbac4c11962b65af842e325a132b871","modified":1542284993000},{"_id":"source/CNAME","hash":"3476d63984d6f43a96cd9834ed9fb4948ed6c85c","modified":1542277634000},{"_id":"themes/icarus/LICENSE","hash":"df00918fa95de563927fd92b26f14c7affdc3052","modified":1542250061000},{"_id":"themes/icarus/README.md","hash":"25c75503f044b817297995a96621c92ce037a098","modified":1542250061000},{"_id":"themes/icarus/_config.yml","hash":"fa297f83aa650787b02ab36c2d716682f925aacd","modified":1542287668000},{"_id":"themes/icarus/package.json","hash":"1bc52ef10a33df23e56bd73c927f605019c87d41","modified":1542250061000},{"_id":"source/_posts/manual-deploy-ceph.md","hash":"14fe00cb4408311c2d536b13ef4fb9b73be35273","modified":1542284151000},{"_id":"source/about/index.md","hash":"3094693de0d30067fca4424611d503b5f91daa37","modified":1542277600000},{"_id":"source/categories/index.md","hash":"55bee2cb88da438a2e8b1f29b1d7e954c07a9e60","modified":1542288000000},{"_id":"source/tags/index.md","hash":"e999413d6392c34156b5c6e9273f9069f9e6d92d","modified":1542256426000},{"_id":"themes/icarus/languages/en.yml","hash":"ade241498b85503a8953a1deca963222f47067a7","modified":1542250061000},{"_id":"themes/icarus/languages/es.yml","hash":"d7432219be5bee4cb569331378ade61b749688e0","modified":1542250061000},{"_id":"themes/icarus/languages/fr.yml","hash":"cb3e597cbec7e8f458858c457bafd1f3a225083d","modified":1542250061000},{"_id":"themes/icarus/languages/id.yml","hash":"70ec9ab2ac04cf882e81377ca5ad15bf8adceca8","modified":1542250061000},{"_id":"themes/icarus/languages/ja.yml","hash":"ff972961e5f468a695d80d21b62c3e9032cdf561","modified":1542250061000},{"_id":"themes/icarus/languages/ko.yml","hash":"7c4ad4577dc0577ad2ca1c0410507f5e5fadf530","modified":1542250061000},{"_id":"themes/icarus/languages/pt-BR.yml","hash":"3c5d5293575593705b9a2dfa9d97b017eb4bc8c3","modified":1542250061000},{"_id":"themes/icarus/languages/ru.yml","hash":"d1aab2b0c939d0c6020f881d664b660a01ee7327","modified":1542250061000},{"_id":"themes/icarus/languages/tr.yml","hash":"8b7eb6aec264db50dbabea89f680acca256f4cd1","modified":1542250061000},{"_id":"themes/icarus/languages/zh-CN.yml","hash":"3dc8ec524805afd090438be717908750da439204","modified":1542250061000},{"_id":"themes/icarus/languages/zh-TW.yml","hash":"d8d96a0a17c20af11919ce036e87379a6b163db9","modified":1542250061000},{"_id":"themes/icarus/layout/.DS_Store","hash":"de7d0a6e507b0c9077f498d187f0685511402a4d","modified":1542284988000},{"_id":"themes/icarus/layout/archive.ejs","hash":"c1ecf667f40f34d61ab33eed46bab143eb1af36d","modified":1542250061000},{"_id":"themes/icarus/layout/categories.ejs","hash":"aa95629b770cff8cca9d663aeb6b17928f070de5","modified":1542250061000},{"_id":"themes/icarus/layout/category.ejs","hash":"1d407f9176db84e83062c52ad4755aaea9e74401","modified":1542250061000},{"_id":"themes/icarus/layout/index.ejs","hash":"43e971ebc35657b18e08a049559790348a16666f","modified":1542250061000},{"_id":"themes/icarus/layout/layout.ejs","hash":"68dce13bc3e8dee1ab50ab80576ab722157e119a","modified":1542250061000},{"_id":"themes/icarus/layout/page.ejs","hash":"50170783bac99946ae8af483920568de9b2d9801","modified":1542250061000},{"_id":"themes/icarus/layout/post.ejs","hash":"50170783bac99946ae8af483920568de9b2d9801","modified":1542250061000},{"_id":"themes/icarus/layout/tag.ejs","hash":"f6c220d4e5c231028bc71ddc11aec97d7b5a9943","modified":1542250061000},{"_id":"themes/icarus/layout/tags.ejs","hash":"b0fcea68d7c11e5899bf0375d80997685111653f","modified":1542250061000},{"_id":"themes/icarus/scripts/meta.js","hash":"1993754a2f3dffa283fa0538eb8f056385b69ad4","modified":1542250061000},{"_id":"themes/icarus/scripts/thumbnail.js","hash":"e667a611f9baac270281b765832020d50bf8fb7f","modified":1542250061000},{"_id":"themes/icarus/source/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1542254832000},{"_id":"themes/icarus/_source/about/index.md","hash":"2847759c65295fdc47685cc32e10ae30b2f022ae","modified":1542250061000},{"_id":"themes/icarus/_source/categories/index.md","hash":"55bee2cb88da438a2e8b1f29b1d7e954c07a9e60","modified":1542250061000},{"_id":"themes/icarus/_source/tags/index.md","hash":"e999413d6392c34156b5c6e9273f9069f9e6d92d","modified":1542250061000},{"_id":"themes/icarus/layout/comment/counter.ejs","hash":"59abd552086c26cb0a6fd86d18ce380c3b1b3c55","modified":1542250061000},{"_id":"themes/icarus/layout/comment/disqus.ejs","hash":"1b32a90f400dc580f4b8298de75b94429ca6de68","modified":1542250061000},{"_id":"themes/icarus/layout/comment/duoshuo.ejs","hash":"ce46d7410a99b57704da32e9d09071cef6c9fa93","modified":1542250061000},{"_id":"themes/icarus/layout/comment/facebook.ejs","hash":"5ee16430a4435c2fead0275ff83fc98092d73d4c","modified":1542250061000},{"_id":"themes/icarus/layout/comment/index.ejs","hash":"0913444317759c3ff0588ca3aa4a6a89b6595307","modified":1542250061000},{"_id":"themes/icarus/layout/comment/isso.ejs","hash":"4f8b81ff5bb418ec11ce080d515f247bfe436014","modified":1542250061000},{"_id":"themes/icarus/layout/comment/scripts.ejs","hash":"305aa07646ab03e00d8239a811f4ec6f75751e1e","modified":1542250061000},{"_id":"themes/icarus/layout/comment/youyan.ejs","hash":"6fe807992832939caf6c3e7651d052df9520d88e","modified":1542250061000},{"_id":"themes/icarus/layout/common/article.ejs","hash":"7c6ee7cbf1ce00e2bd4d1bb6c549a26d14b64d09","modified":1542285875000},{"_id":"themes/icarus/layout/common/footer.ejs","hash":"79ad7f2c8ab0662acfc754ad314522720d010533","modified":1542250061000},{"_id":"themes/icarus/layout/common/head.ejs","hash":"44f30945882afd27c89da2173da501fb1b531488","modified":1542250061000},{"_id":"themes/icarus/layout/common/header.ejs","hash":"738c6a923b2a6de6a81c4892c8a47e03d8b34f88","modified":1542250061000},{"_id":"themes/icarus/layout/common/profile.ejs","hash":"500f05cd15633b004a967ca4802dae9120a2d613","modified":1542250061000},{"_id":"themes/icarus/layout/common/scripts.ejs","hash":"c0a1a9e53f89440c42c325d5bd8c7234652c8937","modified":1542250061000},{"_id":"themes/icarus/layout/common/sidebar.ejs","hash":"2cd62b3efaa3da7bdb6d40d33fdce8e4e28b09ba","modified":1542287544000},{"_id":"themes/icarus/layout/common/thumbnail.ejs","hash":"1b70f8a98cd8650b159bda858dbee38dbdb7f0c5","modified":1542250061000},{"_id":"themes/icarus/layout/common/timeline.ejs","hash":"6420e34e0332c9b6670011519f341340db989343","modified":1542250061000},{"_id":"themes/icarus/layout/plugin/baidu-analytics.ejs","hash":"6a7bee18e666e627e62541a5e30906f87ba1bfe8","modified":1542250061000},{"_id":"themes/icarus/layout/plugin/scripts.ejs","hash":"4fdb85e6730530f2d262041b41d1ead1b87dfd88","modified":1542250061000},{"_id":"themes/icarus/layout/plugin/google-analytics.ejs","hash":"349f08b6521a16e79046b1f94f04317ac74f556e","modified":1542250061000},{"_id":"themes/icarus/layout/search/baidu.ejs","hash":"3e603a702d20c53fd3bcbeb570a16a86d54781ce","modified":1542250061000},{"_id":"themes/icarus/layout/search/index-mobile.ejs","hash":"50a727ac1dfe3073eb6fa6699ba01e66f4ac41c0","modified":1542250061000},{"_id":"themes/icarus/layout/search/index.ejs","hash":"24935e32e61d4706454b174ea3bed0726ae7fb34","modified":1542250061000},{"_id":"themes/icarus/layout/search/insight.ejs","hash":"130fe3d33ac71da0b50f7fee6a87979f30938a1b","modified":1542250061000},{"_id":"themes/icarus/layout/search/swiftype.ejs","hash":"379e66d2c13526e72e4120c443f95fccf4edef71","modified":1542250061000},{"_id":"themes/icarus/layout/share/addtoany.ejs","hash":"ac180c4c84b73a04d61b17e7dc18c257e20bf59f","modified":1542250061000},{"_id":"themes/icarus/layout/share/bdshare.ejs","hash":"a1e772c5a6f174d585b0c1e574058f75dc8e2898","modified":1542250061000},{"_id":"themes/icarus/layout/share/default.ejs","hash":"ebfb919dc525b3ed61a6a5ee05ee71410eedc541","modified":1542250061000},{"_id":"themes/icarus/layout/share/index.ejs","hash":"2a2c0095b95b11e5692bd8ad6a2337aa644189a2","modified":1542250061000},{"_id":"themes/icarus/layout/share/jiathis.ejs","hash":"21ebaa51e828cba2cefbeeaccb01514643565755","modified":1542250061000},{"_id":"themes/icarus/layout/widget/archive.ejs","hash":"d9ebbb7f6ce2f25df5ae25e4a1fef3c08f7054b9","modified":1542250061000},{"_id":"themes/icarus/layout/widget/category.ejs","hash":"583bda80cf15b3ef11fefbd1b502897dfff40100","modified":1542250061000},{"_id":"themes/icarus/layout/widget/links.ejs","hash":"5e3a4a08ec6c146c14010ca7a03b57fccab6a7f6","modified":1542250061000},{"_id":"themes/icarus/layout/widget/recent_posts.ejs","hash":"2ca923465275fb38a7ac7d67211d6e94a977e957","modified":1542250061000},{"_id":"themes/icarus/layout/widget/tag.ejs","hash":"3b8ae5953990436893da9d68f910ebe592005659","modified":1542250061000},{"_id":"themes/icarus/layout/widget/tagcloud.ejs","hash":"ca8c7bf555fb6ce4904f2c59160548405c2c8a82","modified":1542250061000},{"_id":"themes/icarus/source/css/.DS_Store","hash":"495dc0d217dbc3e7cb0c015a4aa9af3e7011d37f","modified":1542250061000},{"_id":"themes/icarus/source/css/_extend.styl","hash":"9a5c72663c0da1b32ecb6a75773a5ccfb8c467ca","modified":1542250061000},{"_id":"themes/icarus/source/css/_variables.styl","hash":"2d3711e9ee47069c17b91e30285833a65d219ac4","modified":1542250061000},{"_id":"themes/icarus/source/css/style.styl","hash":"367fd86ba213ced68052c64cf5895ac146bf7785","modified":1542250061000},{"_id":"themes/icarus/source/js/insight.js","hash":"6ee84c42c2b230ff9e9bf605a444bd671d44f9e3","modified":1542250061000},{"_id":"themes/icarus/source/js/main.js","hash":"1faffdc7aa7f0d28e85edbf49c99de3ad0b65753","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/banner.ejs","hash":"47ced3f03525698c79c6b1c07b48383fb6c496b2","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/category.ejs","hash":"75c9dda2e7ec041943855ca163a6b1c4c8b4f260","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/date.ejs","hash":"45cb0bcad461036cdd1fe2e3fbb5f2f19940025c","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/gallery.ejs","hash":"659f019761116313169148ec61773e7b84abb739","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/nav.ejs","hash":"d7cd611e642327f33dff3963ef869c2b46824a11","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/tag.ejs","hash":"2e966216256321aa0c76fe1b9be689601c76ef31","modified":1542250061000},{"_id":"themes/icarus/layout/common/post/title.ejs","hash":"669ddb46fefa100856588351a7a2d30ad996b755","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/agate.styl","hash":"601eb70448a16b918df132f6fc41e891ae053653","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/arduino-light.styl","hash":"15e8572585cd708221c513dea4bdd89d8fe56c10","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/androidstudio.styl","hash":"65d09f1b0e81c6a182f549fd3de51e59823c97ae","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/arta.styl","hash":"1a5accc115f41d1b669ed708ac6a29abac876599","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/ascetic.styl","hash":"32cff3bef6fac3760fe78f203096477052a90552","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-cave-dark.styl","hash":"bc647b2c1d971d7cc947aa1ed66e9fd115261921","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-dune-dark.styl","hash":"df50a85a4b14c7ca6e825d665594b91229d0e460","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-cave-light.styl","hash":"a5be0744a7ecf4a08f600ade4cfd555afc67bc15","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-dune-light.styl","hash":"931435fbc6f974e8ce9e32722680035d248a9dc1","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-estuary-dark.styl","hash":"d84382bc8298f96730757391d3e761b7e640f406","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-estuary-light.styl","hash":"344276ca9b27e51d4c907f76afe5d13cf8e60bdf","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-forest-dark.styl","hash":"57c154c6045a038dc7df0a25927853e10bf48c4a","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-forest-light.styl","hash":"95228d9f2102fad425536aac44b80b2cba1f5950","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-heath-dark.styl","hash":"b0cf13b2233e7bc38342032d2d7296591a4c2bcf","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-heath-light.styl","hash":"8c8c2e445abef85273be966d59770e9ced6aac21","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-lakeside-dark.styl","hash":"bb0a8c4ad0dd8e3e7de7122ddf268fc42aa94acb","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-lakeside-light.styl","hash":"2c54cb9bdb259ae3b5b29f63ac2469ed34b08578","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-plateau-dark.styl","hash":"09c64f1a7052aec9070c36c0431df25216afaea1","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-plateau-light.styl","hash":"d1a05fdd1ededc9063d181ab25bad55a164aeb4a","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-savanna-dark.styl","hash":"a16c919a1ccf2f845488078fb341381bec46b1f3","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-savanna-light.styl","hash":"f8244c93711c7cb59dd79d2df966806b30d171ea","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-seaside-dark.styl","hash":"ce233a101daea7124cbfcd34add43ccfe2e1e1c7","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-seaside-light.styl","hash":"0597342da6e2d0c5bdcc7d42dabb07322b1a4177","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-sulphurpool-dark.styl","hash":"414b0cfc142f70afe359c16450b651e28bf7325a","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/atelier-sulphurpool-light.styl","hash":"efa52713efc468abeeb2b9299704371583b857de","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/brown-paper.styl","hash":"c2326ba20a5020a66ca7895258d18833327d4334","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/brown-papersq.png","hash":"3a1332ede3a75a3d24f60b6ed69035b72da5e182","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/codepen-embed.styl","hash":"f4dcc84d8e39f9831a5efe80e51923fc3054feb0","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/color-brewer.styl","hash":"2a439d6214430e2f45dd4939b4dfe1fe1a20aa0f","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/dark.styl","hash":"71ce56d311cc2f3a605f6e2c495ccd7236878404","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/darkula.styl","hash":"ad0d5728d21645039c9f199e7a56814170ed3bab","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/docco.styl","hash":"b1c176378bb275f2e8caa759f36294e42d614bf1","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/far.styl","hash":"d9928010ffe71e80b97a5afcba1a4975efdd7372","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/foundation.styl","hash":"bf8ddc94b4ad995b8b8805b5a4cf95004553fdac","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/github-gist.styl","hash":"48211a03d33e7f7ada0b261162bea06676155a71","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/github.styl","hash":"3336aeba324c6d34a6fd41fef9b47bc598f7064c","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/googlecode.styl","hash":"bda816beee7b439814b514e6869dc678822be1bc","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/grayscale.styl","hash":"bf37d8b8d1e602126c51526f0cc28807440228ed","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/highlightjs.styl","hash":"0e198b7a59191c7a39b641a4ddd22c948edb9358","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/hopscotch.styl","hash":"b374c6550b89b4751aedc8fbc3cf98d95bd70ead","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/hybrid.styl","hash":"ea8d7ddc258b073308746385f5cb85aabb8bfb83","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/idea.styl","hash":"a02967cb51c16a34e0ee895d33ded2b823d35b21","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/index.styl","hash":"903a1f2c6ec62cf76a44f92a2dbb52178a4ce94a","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/ir-black.styl","hash":"693078bbd72a2091ed30f506cc55949600b717af","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/kimbie.dark.styl","hash":"45dbb168f22d739d0109745d2decd66b5f94e786","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/kimbie.light.styl","hash":"61f8baed25be05288c8604d5070afbcd9f183f49","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/magula.styl","hash":"16d323f989b1420a0f72ef989242ece9bf17a456","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/mono-blue.styl","hash":"4c89a6ae29de67c0700585af82a60607e85df928","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/monokai-sublime.styl","hash":"25aa2fc1dbe38593e7c7ebe525438a39574d9935","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/monokai.styl","hash":"5a4fe9f957fd7a368c21b62a818403db4270452f","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/obsidian.styl","hash":"55572bbcfee1de6c31ac54681bb00336f5ae826d","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/paraiso-dark.styl","hash":"f1537bd868579fa018ecdbfd2eb922dcf3ba2cac","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/paraiso-light.styl","hash":"d224d1df0eb3395d9eea1344cee945c228af2911","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/pojoaque.jpg","hash":"c5fe6533b88b21f8d90d3d03954c6b29baa67791","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/pojoaque.styl","hash":"77dae9dc41945359d17fe84dbd317f1b40b2ee33","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/railscasts.styl","hash":"acd620f8bb7ff0e3fe5f9a22b4433ceef93a05e6","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/rainbow.styl","hash":"ce73b858fc0aba0e57ef9fb136c083082746bc1d","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/school-book.png","hash":"711ec983c874e093bb89eb77afcbdf6741fa61ee","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/school-book.styl","hash":"d43560fe519a931ce6da7d57416d7aa148441b83","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/solarized-light.styl","hash":"aa0dd3fd25c464183b59c5575c9bee8756b397f2","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/solarized-dark.styl","hash":"702b9299a48c90124e3ac1d45f1591042f2beccc","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/sunburst.styl","hash":"a0b5b5129547a23865d400cfa562ea0ac1ee3958","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night-blue.styl","hash":"8b3087d4422be6eb800935a22eb11e035341c4ba","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night-bright.styl","hash":"0ac6af6ecb446b5b60d6226748e4a6532db34f57","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night.styl","hash":"19b3080d4b066b40d50d7e7f297472482b5801fd","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/tomorrow-night-eighties.styl","hash":"fa57b3bb7857a160fc856dbe319b31e30cc5d771","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/tomorrow.styl","hash":"15779cf6846725c7c35fc56cac39047d7e0aec1c","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/vs.styl","hash":"959a746f4b37aacb5d1d6ff1d57e0c045289d75d","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/xcode.styl","hash":"5e8532ae8366dcf6a4ef5e4813dc3d42ab3d0a50","modified":1542250061000},{"_id":"themes/icarus/source/css/_highlight/zenburn.styl","hash":"fc5ec840435dad80964d04519d3f882ddc03746a","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/archive.styl","hash":"d35088c83ddd7a197d6d94e16a2ce3a7e29fa1dc","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/article.styl","hash":"49159a9d8a42d8478d66b93cf5c6ad20ee71b480","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/article_backup.styl","hash":"512b9252e1799b93a17c4ad847b0586814a030b4","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/footer.styl","hash":"484776654e4c1691dc844e6e93786a08855c1c99","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/comment.styl","hash":"784646796184d4f27918c22395288a2fafbf9554","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/header.styl","hash":"ce832196eb5761364f3d9af7344e616b031bb8a7","modified":1542254806000},{"_id":"themes/icarus/source/css/_partial/insight.styl","hash":"19833cd127f26ad90b06c115f8a96a30e0c0e53b","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/profile.styl","hash":"b0f9b4534c4949ecb9f8540ed04e3e440065c4cd","modified":1542251420000},{"_id":"themes/icarus/source/css/_partial/timeline.styl","hash":"c813b98f4fc45b64d2e07e5d944745a654c8c943","modified":1542250061000},{"_id":"themes/icarus/source/css/_partial/sidebar.styl","hash":"f528ca7064d9fcecd737b9b71c9c54601365d7d3","modified":1542250061000},{"_id":"themes/icarus/source/css/_util/grid.styl","hash":"93fb6f1e2f40cd7d88ad0d56dd73d3f9a7bc853e","modified":1542250061000},{"_id":"themes/icarus/source/css/_util/mixin.styl","hash":"c8e1ddfc0fe9108bab592c7a73b73ce9344991fd","modified":1542250061000},{"_id":"themes/icarus/source/css/images/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1542275395000},{"_id":"themes/icarus/source/css/images/avatar.png","hash":"0d8236dcca871735500e9d06bbdbe0853ed6775b","modified":1542250061000},{"_id":"themes/icarus/source/css/images/logo.png","hash":"e606a0584f98268b2fe92303f3254520862ef659","modified":1542250061000},{"_id":"themes/icarus/source/css/images/thumb-default-small.png","hash":"e8403b97ed9251f9f5207765b0ce796c5000b4ba","modified":1542250061000},{"_id":"themes/icarus/source/css/images/whale.png","hash":"5e59a7b7bed8480212a40ee5b0723cbfe9f27c52","modified":1542250061000},{"_id":"themes/icarus/source/libs/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1542250061000},{"_id":"themes/icarus/source/libs/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/styles.css","hash":"5ca6e111046232bde112d33201a60532aee7d3c4","modified":1542250061000},{"_id":"themes/icarus/source/libs/source-code-pro/styles.css","hash":"93c308012738728f906cd4c5cfdb34189e0c712b","modified":1542250061000},{"_id":"themes/icarus/source/css/images/favicon.ico","hash":"72e198149b2809bc8af629da284399985e9023ec","modified":1542250061000},{"_id":"themes/icarus/source/css/images/horse.jpg","hash":"abe614ab9e08706a84523518ceabb36a3792302c","modified":1542250449000},{"_id":"themes/icarus/source/libs/font-awesome/css/font-awesome.css","hash":"b5020c3860669185ba3f316fa7332cdf5c06f393","modified":1542250061000},{"_id":"themes/icarus/source/libs/font-awesome/css/font-awesome.min.css","hash":"7cd5a3384333f95c3d37d9488ad82cd6c4b03761","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-fb-comment-box.css","hash":"844ce27b8488968bccb3e50bb49184ba2aae0625","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-fb-comment-box.css.map","hash":"51e9df39edf0faa3f38c1bab0c1fa6c922b9edcb","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-fb-comment-box.min.css","hash":"05830fadb8454f39dcc98c8686eb4d5c24b71fc0","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-transitions.css","hash":"7871c28498d74451d6aa438c8d3a1817810a1e19","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-transitions.css.map","hash":"50c3348638b4d82fa08a449c690e8d2bb593005d","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lightgallery.css","hash":"bef55316a32e512d5a8940e5d0bfe8bf7a9c5c61","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lg-transitions.min.css","hash":"5c22e2073a4c96d6212c72135391b599e8d1359f","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lightgallery.css.map","hash":"3175b4107078674d25798979f7666f4daf31e624","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/css/lightgallery.min.css","hash":"c9a2e19c932b56f4a2ce30c98910d10b74edb38a","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/img/loading.gif","hash":"607810444094b8619fa4efa6273bc2a7e38dd4b4","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/img/vimeo-play.png","hash":"6190254f2804904a4a1fa1eb390dfd334e416992","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/img/video-play.png","hash":"3ea484cdc04d2e4547f80cbf80001dcf248c94ef","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/img/youtube-play.png","hash":"fea6df9d9d43151f9c9d15f000adb30eb3e26fc4","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-autoplay.js","hash":"426bb78b93acfc39d533ea2bab1cec8dc289cf24","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-autoplay.min.js","hash":"d845741bcaf961579622880eb2a445257efad1ac","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-fullscreen.js","hash":"65c47ac65362854ba44b00a010bb01e3630209d8","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-fullscreen.min.js","hash":"b6b9e4022700b7faf2a5a175ba44a3bd938fdd20","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-hash.js","hash":"15d16516c5642d3de1566ff8fc9160136ccaa405","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-hash.min.js","hash":"43f1e1e720ab0e241c19b83aa26bd6848eab8edc","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-pager.js","hash":"8092c692b244bb26343eb03b91bd97deb9dafc9c","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-pager.min.js","hash":"25caa6ff65b1c6dee09941e795ae2633bdbab211","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-share.js","hash":"b7fb5f6474911060a351b0a6fe9dbb9ac3fb22aa","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-share.min.js","hash":"39c615f07c5d3aaa65a2c3068a30fdd6dd5c372d","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-thumbnail.js","hash":"3a6476b6df1d2bef4a21861a78776282a7a11ef1","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-thumbnail.min.js","hash":"18dd7d2909d1bfd6852f031d03e774b4428c512b","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-video.js","hash":"4f99b598f6bb18de9eca8c45c5b4373a03962367","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-video.min.js","hash":"032c001ab045a69856f9c3ed4a2a3bf12a8e310f","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-zoom.min.js","hash":"15b49f9728439819ece15e4295cce254c87a4f45","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lg-zoom.js","hash":"a758e2c8fcf710f9ff761da0eea0ab9321f3484d","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lightgallery.js","hash":"3cd19b33ba99efd5ba1d167da91720566d274b2c","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","hash":"c4248ea800bd5608344ce163f5658b57e7ef9410","modified":1542250061000},{"_id":"themes/icarus/source/libs/lightgallery/js/lightgallery.min.js","hash":"956ef9b706755318da69ad0b5d7786339d831251","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","hash":"e0350190d720a8fec0557ab47b318ec4e4486448","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","hash":"2c5b039b57f62625e88226a938679ec937431ad1","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","hash":"22413bb8bfb78608c1e25aa1ed5c1f38557df79f","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","hash":"63eb74ef040aade256f2274a7f31a914edddb0ea","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","hash":"328a22fe3eec71ad9e5ece4d67dd62e79dab6b7f","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","hash":"4dc6d7174ea6d89f4c45e43e1bfc3e03d8ffebaf","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","hash":"415eee05976ab8b2471602a5ddb78a6c58fc21aa","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","hash":"a0b0c389cf46d63c850e61fed572485ff0b68183","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","hash":"c5f29fed6632efe0aa83318369f0d8c4061b775b","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","hash":"be201d32a9aa5d186723ebb3c538be691aa8c53a","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","hash":"afc44700053c9a28f9ab26f6aec4862ac1d0795d","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","hash":"113978181dcac77baecef6115a9121d8f6e4fc3a","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","hash":"5067c81462c15422853c94d21a1726865a61634f","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","hash":"b366f2fda2e524eb5ef50058eefff249a3b96e6c","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","hash":"d22904914469be735490e3c8cb093c7862896dd5","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","hash":"ae80fb3cd16339aa7b5da280ab53975523dcaac2","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","hash":"e75607ba1417181397c700775b84303d5a2957b9","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","hash":"b85efde42fa3a03c32b1d31c6cd74c622fc7916c","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","hash":"d0b40a7848703556c6631f24e961a98ca5829255","modified":1542250061000},{"_id":"themes/icarus/source/libs/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","hash":"be365eca44760ce3fc9b377c43d4634958479c69","modified":1542250061000},{"_id":"themes/icarus/source/libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","hash":"942addaec4d3a60af33947a84a3d85f926015947","modified":1542250061000},{"_id":"themes/icarus/source/libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","hash":"b0e0bb5ef78db8b15d430d0b9be9d4329289a310","modified":1542250061000},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1542250061000},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1542250061000},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1542250061000},{"_id":"themes/icarus/source/libs/jquery/2.1.3/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1542250061000},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1542250061000},{"_id":"themes/icarus/source/css/images/profile_pic.jpg","hash":"dec900407c9f26db3e7475823e4f65d8bf3c19f2","modified":1542256651000},{"_id":"themes/icarus/source/libs/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1542250061000},{"_id":"themes/icarus/source/libs/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1542250061000},{"_id":"public/content.json","hash":"76cbd1b1138a3661b56eee918263673aa0d0b3e2","modified":1542288021067},{"_id":"public/about/index.html","hash":"2543d755b0d6578fa67e5a2cde566590fa56bfd8","modified":1542288021336},{"_id":"public/categories/index.html","hash":"22fa3e8b5acf72c43df96bed3ecbcdf0e0d37593","modified":1542288021336},{"_id":"public/tags/index.html","hash":"96b5822f8ebe875e26d5ff4691d697dd05a4cad7","modified":1542288021336},{"_id":"public/archives/index.html","hash":"6b8e52867430fd3fe963c4f7ad35be0e7da7ff25","modified":1542288021337},{"_id":"public/archives/2018/index.html","hash":"55973e2c0409e87279ed1b0ff7cacdb5093508a4","modified":1542288021337},{"_id":"public/archives/2018/11/index.html","hash":"9cb3ce24a1fb5b5c9e9746215732bc15092f3bf4","modified":1542288021337},{"_id":"public/categories/ceph/index.html","hash":"0a088ce53e724cc12c0a5572b2fc903333748d64","modified":1542288021337},{"_id":"public/index.html","hash":"bc9de2bae187674d2b894011d45ccc346bc96ea1","modified":1542288021337},{"_id":"public/tags/ceph/index.html","hash":"d45b0c5546b70b5318b6a37294c31c36b6e7f8dd","modified":1542288021337},{"_id":"public/post/c3d7e91e.html","hash":"222eba1f65f0000835f115c311067f6f0fd22809","modified":1542288021337},{"_id":"public/CNAME","hash":"3476d63984d6f43a96cd9834ed9fb4948ed6c85c","modified":1542288021346},{"_id":"public/css/images/avatar.png","hash":"0d8236dcca871735500e9d06bbdbe0853ed6775b","modified":1542288021346},{"_id":"public/css/images/logo.png","hash":"e606a0584f98268b2fe92303f3254520862ef659","modified":1542288021346},{"_id":"public/css/images/thumb-default-small.png","hash":"e8403b97ed9251f9f5207765b0ce796c5000b4ba","modified":1542288021347},{"_id":"public/css/images/whale.png","hash":"5e59a7b7bed8480212a40ee5b0723cbfe9f27c52","modified":1542288021347},{"_id":"public/libs/lightgallery/css/lg-fb-comment-box.css.map","hash":"51e9df39edf0faa3f38c1bab0c1fa6c922b9edcb","modified":1542288021347},{"_id":"public/libs/lightgallery/css/lg-transitions.css.map","hash":"50c3348638b4d82fa08a449c690e8d2bb593005d","modified":1542288021347},{"_id":"public/libs/lightgallery/css/lightgallery.css.map","hash":"3175b4107078674d25798979f7666f4daf31e624","modified":1542288021347},{"_id":"public/libs/lightgallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1542288021347},{"_id":"public/libs/lightgallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1542288021347},{"_id":"public/libs/lightgallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1542288021347},{"_id":"public/libs/lightgallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1542288021347},{"_id":"public/libs/lightgallery/img/loading.gif","hash":"607810444094b8619fa4efa6273bc2a7e38dd4b4","modified":1542288021348},{"_id":"public/libs/lightgallery/img/vimeo-play.png","hash":"6190254f2804904a4a1fa1eb390dfd334e416992","modified":1542288021348},{"_id":"public/libs/lightgallery/img/video-play.png","hash":"3ea484cdc04d2e4547f80cbf80001dcf248c94ef","modified":1542288021348},{"_id":"public/libs/lightgallery/img/youtube-play.png","hash":"fea6df9d9d43151f9c9d15f000adb30eb3e26fc4","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/59ZRklaO5bWGqF5A9baEERJtnKITppOI_IvcXXDNrsc.woff2","hash":"c4248ea800bd5608344ce163f5658b57e7ef9410","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/K88pR3goAWT7BTt32Z01mxJtnKITppOI_IvcXXDNrsc.woff2","hash":"e0350190d720a8fec0557ab47b318ec4e4486448","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/LWCjsQkB6EMdfHrEVqA1KRJtnKITppOI_IvcXXDNrsc.woff2","hash":"2c5b039b57f62625e88226a938679ec937431ad1","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNShWV49_lSm1NYrwo-zkhivY.woff2","hash":"22413bb8bfb78608c1e25aa1ed5c1f38557df79f","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSj0LW-43aMEzIO6XUTLjad8.woff2","hash":"63eb74ef040aade256f2274a7f31a914edddb0ea","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSq-j2U0lmluP9RWlSytm3ho.woff2","hash":"4dc6d7174ea6d89f4c45e43e1bfc3e03d8ffebaf","modified":1542288021348},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSqaRobkAwv3vxw3jMhVENGA.woff2","hash":"415eee05976ab8b2471602a5ddb78a6c58fc21aa","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSugdm0LZdjqr5-oayXSOefg.woff2","hash":"a0b0c389cf46d63c850e61fed572485ff0b68183","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSv8zf_FOSsgRmwsS7Aa9k2w.woff2","hash":"c5f29fed6632efe0aa83318369f0d8c4061b775b","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/RjgO7rYTmqiVp7vzi-Q5URJtnKITppOI_IvcXXDNrsc.woff2","hash":"be201d32a9aa5d186723ebb3c538be691aa8c53a","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/cJZKeOuBrn4kERxqtaUH3VtXRa8TVwTICgirnJhmVJw.woff2","hash":"afc44700053c9a28f9ab26f6aec4862ac1d0795d","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/u-WUoqrET9fUeobQW7jkRRJtnKITppOI_IvcXXDNrsc.woff2","hash":"113978181dcac77baecef6115a9121d8f6e4fc3a","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBiYE0-AqJ3nfInTTiDXDjU4.woff2","hash":"5067c81462c15422853c94d21a1726865a61634f","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjTOQ_MqJVwkKsUn0wKzc2I.woff2","hash":"b366f2fda2e524eb5ef50058eefff249a3b96e6c","modified":1542288021349},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBjUj_cnvWIuuBMVgbX098Mw.woff2","hash":"d22904914469be735490e3c8cb093c7862896dd5","modified":1542288021350},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBkbcKLIaa1LC45dFaAfauRA.woff2","hash":"ae80fb3cd16339aa7b5da280ab53975523dcaac2","modified":1542288021350},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBo4P5ICox8Kq3LLUNMylGO4.woff2","hash":"e75607ba1417181397c700775b84303d5a2957b9","modified":1542288021350},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBmo_sUJ8uO4YLWRInS22T3Y.woff2","hash":"b85efde42fa3a03c32b1d31c6cd74c622fc7916c","modified":1542288021350},{"_id":"public/libs/open-sans/fonts/xjAJXh38I15wypJXxuGMBr6up8jxqWt8HVA3mDhkV_0.woff2","hash":"d0b40a7848703556c6631f24e961a98ca5829255","modified":1542288021350},{"_id":"public/libs/open-sans/fonts/xozscpT2726on7jbcb_pAhJtnKITppOI_IvcXXDNrsc.woff2","hash":"be365eca44760ce3fc9b377c43d4634958479c69","modified":1542288021350},{"_id":"public/libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasD9V_2ngZ8dMf8fLgjYEouxg.woff2","hash":"942addaec4d3a60af33947a84a3d85f926015947","modified":1542288021350},{"_id":"public/libs/source-code-pro/fonts/mrl8jkM18OlOQN8JLgasDy2Q8seG17bfDXYR_jUsrzg.woff2","hash":"b0e0bb5ef78db8b15d430d0b9be9d4329289a310","modified":1542288021350},{"_id":"public/css/images/favicon.ico","hash":"72e198149b2809bc8af629da284399985e9023ec","modified":1542288021915},{"_id":"public/css/images/horse.jpg","hash":"abe614ab9e08706a84523518ceabb36a3792302c","modified":1542288021916},{"_id":"public/libs/open-sans/fonts/MTP_ySUJH_bn48VBG8sNSpX5f-9o1vgP2EXwfjgl7AY.woff2","hash":"328a22fe3eec71ad9e5ece4d67dd62e79dab6b7f","modified":1542288021917},{"_id":"public/libs/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1542288021917},{"_id":"public/libs/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1542288021917},{"_id":"public/libs/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1542288021917},{"_id":"public/js/main.js","hash":"1faffdc7aa7f0d28e85edbf49c99de3ad0b65753","modified":1542288021923},{"_id":"public/libs/justified-gallery/justifiedGallery.min.css","hash":"13fbcba5e97aa88b748d94d3efc4718475279907","modified":1542288021923},{"_id":"public/libs/open-sans/styles.css","hash":"5ca6e111046232bde112d33201a60532aee7d3c4","modified":1542288021923},{"_id":"public/libs/source-code-pro/styles.css","hash":"93c308012738728f906cd4c5cfdb34189e0c712b","modified":1542288021923},{"_id":"public/libs/lightgallery/css/lg-fb-comment-box.css","hash":"844ce27b8488968bccb3e50bb49184ba2aae0625","modified":1542288021923},{"_id":"public/libs/lightgallery/css/lg-fb-comment-box.min.css","hash":"05830fadb8454f39dcc98c8686eb4d5c24b71fc0","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-autoplay.js","hash":"426bb78b93acfc39d533ea2bab1cec8dc289cf24","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-autoplay.min.js","hash":"d845741bcaf961579622880eb2a445257efad1ac","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-fullscreen.js","hash":"65c47ac65362854ba44b00a010bb01e3630209d8","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-hash.js","hash":"15d16516c5642d3de1566ff8fc9160136ccaa405","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-fullscreen.min.js","hash":"b6b9e4022700b7faf2a5a175ba44a3bd938fdd20","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-hash.min.js","hash":"43f1e1e720ab0e241c19b83aa26bd6848eab8edc","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-pager.js","hash":"8092c692b244bb26343eb03b91bd97deb9dafc9c","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-pager.min.js","hash":"25caa6ff65b1c6dee09941e795ae2633bdbab211","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-share.js","hash":"b7fb5f6474911060a351b0a6fe9dbb9ac3fb22aa","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-share.min.js","hash":"39c615f07c5d3aaa65a2c3068a30fdd6dd5c372d","modified":1542288021924},{"_id":"public/libs/lightgallery/js/lg-video.min.js","hash":"032c001ab045a69856f9c3ed4a2a3bf12a8e310f","modified":1542288021925},{"_id":"public/css/style.css","hash":"2bdffba6be51da60574ea96d85f0c07dffc835d8","modified":1542288021925},{"_id":"public/libs/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1542288021925},{"_id":"public/libs/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1542288021925},{"_id":"public/js/insight.js","hash":"6ee84c42c2b230ff9e9bf605a444bd671d44f9e3","modified":1542288021936},{"_id":"public/libs/lightgallery/js/lg-thumbnail.min.js","hash":"18dd7d2909d1bfd6852f031d03e774b4428c512b","modified":1542288021936},{"_id":"public/libs/lightgallery/js/lg-video.js","hash":"4f99b598f6bb18de9eca8c45c5b4373a03962367","modified":1542288021937},{"_id":"public/libs/lightgallery/js/lg-zoom.min.js","hash":"15b49f9728439819ece15e4295cce254c87a4f45","modified":1542288021937},{"_id":"public/libs/justified-gallery/jquery.justifiedGallery.min.js","hash":"b2683e7a872bc109b1756a65188a37cef7d0bd5c","modified":1542288021943},{"_id":"public/libs/lightgallery/css/lightgallery.css","hash":"bef55316a32e512d5a8940e5d0bfe8bf7a9c5c61","modified":1542288021944},{"_id":"public/libs/lightgallery/css/lightgallery.min.css","hash":"c9a2e19c932b56f4a2ce30c98910d10b74edb38a","modified":1542288021946},{"_id":"public/libs/lightgallery/js/lg-thumbnail.js","hash":"3a6476b6df1d2bef4a21861a78776282a7a11ef1","modified":1542288021946},{"_id":"public/libs/lightgallery/js/lg-zoom.js","hash":"a758e2c8fcf710f9ff761da0eea0ab9321f3484d","modified":1542288021946},{"_id":"public/libs/font-awesome/css/font-awesome.min.css","hash":"7cd5a3384333f95c3d37d9488ad82cd6c4b03761","modified":1542288021953},{"_id":"public/libs/lightgallery/js/lightgallery.min.js","hash":"956ef9b706755318da69ad0b5d7786339d831251","modified":1542288021953},{"_id":"public/libs/lightgallery/css/lg-transitions.min.css","hash":"5c22e2073a4c96d6212c72135391b599e8d1359f","modified":1542288021959},{"_id":"public/libs/font-awesome/css/font-awesome.css","hash":"b5020c3860669185ba3f316fa7332cdf5c06f393","modified":1542288021960},{"_id":"public/libs/lightgallery/css/lg-transitions.css","hash":"7871c28498d74451d6aa438c8d3a1817810a1e19","modified":1542288021965},{"_id":"public/libs/lightgallery/js/lightgallery.js","hash":"3cd19b33ba99efd5ba1d167da91720566d274b2c","modified":1542288021969},{"_id":"public/css/images/profile_pic.jpg","hash":"dec900407c9f26db3e7475823e4f65d8bf3c19f2","modified":1542288021972},{"_id":"public/libs/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1542288021972},{"_id":"public/libs/jquery/2.1.3/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1542288022014}],"Category":[{"name":"ceph","_id":"cjoimgt0e0004ppyg892r6car"}],"Data":[],"Page":[{"layout":"page","_content":"\nhi,大家好！欢迎大家来到我的blog，希望以后能跟各位大佬一起学习进步。\n\n我叫左杨，目前就职于蚂蚁金服人工智能部，从事于蚂蚁人工智能相关的开发工作，对Machine Learning，Deep Learning比较感兴趣。\n","source":"about/index.md","raw":"layout: \"page\"\n---\n\nhi,大家好！欢迎大家来到我的blog，希望以后能跟各位大佬一起学习进步。\n\n我叫左杨，目前就职于蚂蚁金服人工智能部，从事于蚂蚁人工智能相关的开发工作，对Machine Learning，Deep Learning比较感兴趣。\n","date":"2018-11-15T10:26:40.000Z","updated":"2018-11-15T10:26:40.000Z","path":"about/index.html","title":"","comments":1,"_id":"cjoimgszc0000ppyguestb5ra","content":"<p>hi,大家好！欢迎大家来到我的blog，希望以后能跟各位大佬一起学习进步。</p>\n<p>我叫左杨，目前就职于蚂蚁金服人工智能部，从事于蚂蚁人工智能相关的开发工作，对Machine Learning，Deep Learning比较感兴趣。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>hi,大家好！欢迎大家来到我的blog，希望以后能跟各位大佬一起学习进步。</p>\n<p>我叫左杨，目前就职于蚂蚁金服人工智能部，从事于蚂蚁人工智能相关的开发工作，对Machine Learning，Deep Learning比较感兴趣。</p>\n"},{"title":"Categories","layout":"categories","_content":"","source":"categories/index.md","raw":"title: \"Categories\"\nlayout: \"categories\"\n---\n","date":"2018-11-15T13:20:00.000Z","updated":"2018-11-15T13:20:00.000Z","path":"categories/index.html","comments":1,"_id":"cjoimgszd0001ppygmgru7iol","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Tags","layout":"tags","_content":"","source":"tags/index.md","raw":"title: \"Tags\"\nlayout: \"tags\"\n---\n","date":"2018-11-15T04:33:46.000Z","updated":"2018-11-15T04:33:46.000Z","path":"tags/index.html","comments":1,"_id":"cjoimgsze0002ppyg91lfri7e","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"手动部署ceph集群","abbrlink":"c3d7e91e","date":"2018-11-15T07:54:19.000Z","_content":"\n## 1、机器选择\n\n### 1.1 系统要求\n\nceph 最新 LTS 版本 (luminous) 推荐 linux 内核版本 `4.1.4` 及以上, 最低版本要求 `3.10.*`。\n\n\n### 1.2 服务器\n\n这里选择三台服务器来部署ceph集群，一台Mon+五台OSD\n\n------\n\n| 节点            | 服务             | cluster network  | public network   |\n| --------------- | ---------------- | ---------------- | ---------------- |\n| 192.168.226.20  | osd.1,mon.node2  | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.21  | osd.4            | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.22  | osd.2, mon.node1 | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.96  | osd.3,mon.node3  | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.106 | osd.0            | 192.168.226.0/24 | 192.168.226.0/24 |\n\n每个节点只能使用1块磁盘部署osd。所以，集群共有5个`osd`进程，3个`monitor`进程。\n\ncluster network 是处理osd间的数据复制，数据重平衡，osd进程心跳检测的网络，其不对外提供服务，只在各个osd节点间通信，本文使用eth1网卡作为cluster network，三个节点网卡eth1桥接到同一个网桥br1上\n\n\n\n## 2、环境配置 \n\n配置每个节点的host文件，在 `/etc/hosts`文件中添加如下内容：\n\n```shell\n192.168.226.20 ceph-1\n192.168.226.22 ceph-2\n192.168.226.96 ceph-3\n```\n\n### 2.2 ceph节点安装\n\n你的管理节点必须能够通过 SSH 无密码地访问各 Ceph 节点。如果 `ceph-deploy` 以某个普通用户登录，那么这个用户必须有无密码使用 `sudo` 的权限。\n\n#### 2.2.1 安装 NTP\n\n我们建议在所有 Ceph 节点上安装 NTP 服务（特别是 Ceph Monitor 节点），以免因时钟漂移导致故障，详情见[时钟](http://docs.ceph.org.cn/rados/configuration/mon-config-ref#clock)。\n\n```shell\nsudo yum install ntp ntpdate ntp-doc\n```\n\n确保在各 Ceph 节点上启动了 NTP 服务，并且要使用同一个 NTP 服务器，详情见 [NTP](http://www.ntp.org/) 。\n\n#### 2.2.2 安装 SSH 服务器\n\n在**所有 Ceph** 节点上执行如下步骤：\n\n1. 在各 Ceph 节点安装 SSH 服务器（如果还没有）\n\n   ```shell\n   sudo yum install openssh-server\n   ```\n\n2. 确保**所有** Ceph 节点上的 SSH 服务器都在运行。\n\n#### 2.2.3 安装ceph\n\n由于蚂蚁内部物理机不能访问外网，使用以下步骤安装ceph。\n\n在**所有Ceph**节点上执行如下步骤：\n\n下载ceph所有的依赖rpm，并解压缩\n\n```shell\nsudo wget http://qianli-lzh.oss-cn-hangzhou-zmf.aliyuncs.com/bill_inference_public%2Fceph.tar\nsudo tar -xvf bill_inference_public%2Fceph.tar\n```\n\n手动安装所有的rpm\n\n```shell\nsudo rpm -ivh --force --nodeps ceph/*.rpm\n```\n\n验证ceph是否正确安装\n\n```shell\nceph -v\nceph version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)\n```\n\n#### 2.2.4 关闭防火墙\n\n```shell\nsudo sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\nsudo setenforce 0\nsudo systemctl stop firewalld \nsudo systemctl disable firewalld\n```\n\n## 3、集群搭建\n\n### 3.1 搭建Mon集群 (使用admin账户)\n\n**创建配置文件**\n\n在**每台节点机器**上创建配置文件`/etc/ceph/ceph.conf`：\n\n```shell\n[global]\nfsid = 932XXXXX-fba7-XXXX-9526-a858c613f468\nmon initial members = e15p13447.ew9\nmon host = 192.168.226.20,192.168.226.22,192.168.226.96\nrbd default features = 1\nauth_cluster_required = none\nauth_service_required = none\nauth_client_required = none\npublic network = 192.168.226.0/24\ncluster network = 192.168.226.0/24\nosd journal size = 1024\nosd pool default size = 2\nosd pool default min size = 1\nosd pool default pg num = 128\nosd pool default pgp num = 128\nosd crush chooseleaf type = 1\nmon_max_pg_per_osd = 200\n\n[mds.ceph-1]\nhost = ceph-1\n[mds.ceph-2]\nhost = ceph-2\n[mds.ceph-3]\nhost = ceph-3\n\n[mon]\nmon allow pool delete = true\n```\n\n其中 `fsid` 是为集群分配的一个 uuid, 初始化 mon 节点其实只需要这一个配置就够了。\n`mon host` 配置 ceph 命令行工具访问操作 ceph 集群时查找 mon 节点入口。\nceph 集群可包含多个 mon 节点实现高可用容灾, 避免单点故障。\n`rbd default features = 1` 配置 rbd 客户端创建磁盘时禁用一些需要高版本内核才能支持的特性。\n\n#### 3.1.2 主mon节点 （192.168.226.20）\n\n1、为此集群创建密钥环、并生成Monitor密钥 (3台机器一样)\n\n```shell\nsudo ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'\n```\n\n2、生成管理员密钥环，生成 `client.admin` 用户并加入密钥环 (3台机器一样)\n\n```shell\nsudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *' \n```\n\n3、把 `client.admin` 密钥加入 `ceph.mon.keyring`  (3台机器一样)\n\n```shell\nsudo ceph-authtool /tmp/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring\n```\n\n4、用规划好的主机名、对应 IP 地址、和 FSID 生成一个Monitor Map，并保存为 `/tmp/monmap`\n\n```shell\nhost_name=`hostname`\nsudo monmaptool --create --add $host_name 192.168.226.20  --fsid 932XXXXX-fba7-XXXX-9526-a858c613f468 /tmp/monmap --clobber\n```\n\n5、在Monitor主机上分别创建数据目录\n\n```shell\nhost_name=`hostname`\n#在admin账户下\nsudo mkdir /var/lib/ceph/mon/ceph-$host_name/\n```\n\n6、用Monitor Map和密钥环组装守护进程所需的初始数据\n\n```shell\nsudo ceph-mon --mkfs -i $host_name --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring\n```\n\n7、建一个空文件 `done` ，表示监视器已创建、可以启动了\n\n```shell\nsudo touch /var/lib/ceph/mon/ceph-$host_name/done\n```\n\n8、启动Monitor\n\n```shell\n#sudo ceph-mon -f --cluster ceph --id $host_name &\nsudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service\nsudo systemctl start ceph-mon@$host_name\nsudo systemctl enable ceph-mon@$host_name\n```\n\n9、确认下集群在运行\n\n```shell\nceph -s\n```\n\n事例：\n\n```shell\n  cluster:\n    id:     932XXXXX-fba7-XXXX-9526-a858c613f468\n    health: HEALTH_OK\n \n  services:\n    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3\n    mgr: no daemons active\n    osd: 0 osds: 0 up, 0 in\n \n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0 objects, 0B\n    usage:   0B used, 0B / 0B avail\n    pgs:     \n```\n\n#### 3.1.2 从mon节点 (192.168.226.22 & 192.168.226.96)\n\n```shell\nhost_name=`hostname`\nsudo ceph mon getmap -o /tmp/monmap\nsudo rm -rf /var/lib/ceph/mon/ceph-$host_name\nsudo ceph-mon -i $host_name --mkfs --monmap /tmp/monmap\nsudo chown -R ceph:ceph /var/lib/ceph/mon/ceph-$host_name/\n#nohup ceph-mon -f --cluster ceph --id $host_name --setuser ceph --setgroup ceph &\n#ceph-mon -f --cluster ceph --id $host_name &\nsudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service\nsudo systemctl start ceph-mon@$host_name\nsudo systemctl enable ceph-mon@$host_name\n```\n\n\n\n### 3.2 创建ceph-mgr\n\n#### 3.2.1 创建用户 openstack 用于 MGR 监控\n\n```shell\nceph auth get-or-create mgr.openstack mon 'allow *' osd 'allow *' mds 'allow *'\n输出：\n[mgr.openstack]\n        key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxugvXkLfgauLA==\n```\n\n需要将之前创建的用户密码存放至对应位置\n\n```shell\nmkdir /var/lib/ceph/mgr/ceph-openstack\nceph auth get mgr.openstack -o  /var/lib/ceph/mgr/ceph-openstack/keyring\nexported keyring for mgr.openstack\n```\n\n#### 3.2.2 启动mgr\n\n```shell\nceph-mgr -i openstack\n```\n\n监控状态\n\n```shell\n$ceph -s\n  cluster:\n    id:     932e88a6-fba7-45a9-9526-a858c613f468\n    health: HEALTH_OK\n \n  services:\n    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3\n    mgr: openstack(active)\n    mds: cephfs-1/1/1 up  {0=2=up:active}, 2 up:standby\n    osd: 3 osds: 3 up, 3 in\n \n  data:\n    pools:   2 pools, 256 pgs\n    objects: 21 objects, 3.04KiB\n    usage:   3.32GiB used, 1.17TiB / 1.17TiB avail\n    pgs:     256 active+clean\n```\n\n当 mgr 服务被激活之后, service 中 mgr 会显示 mgr-$name(active) \ndata 部分信息将变得可用\n\n### 3.3 手动搭建osd集群(三台机器上做相同的操作，注意osd_id的变化)\n\n添加一个新osd，`id`可以省略，ceph会自动使用最小可用整数，第一个osd从0开始\n\n```shell\n#ceph osd create {id}\nceph osd create\n0\n```\n\n#### 3.3.1 初始化osd目录\n\n创建osd.0目录，目录名格式`{cluster-name}-{id}`\n\n```shell\n#mkdir /var/lib/ceph/osd/{cluster-name}-{id}\nsudo mkdir /var/lib/ceph/osd/ceph-0\n```\n\n挂载osd.0的数据盘/dev/sdb2\n\n```shell\nsudo mkfs.xfs /dev/sdb2\nsudo mount /dev/sdb2 /var/lib/ceph/osd/ceph-0\n```\n\n初始化osd数据目录\n\n```shell\n# sudo ceph-osd -i {id} --mkfs --mkkey\nsudo ceph-osd -i 0 --mkfs --mkkey\n#--mkkey要求osd数据目录为空\n#这会创建osd.0的keyring /var/lib/ceph/osd/ceph-0/keyring\n```\n\n初始化后，默认使用普通文件/var/lib/ceph/osd/ceph-3/journal作为osd.0的journal分区，普通文件作为journal分区性能不高，若只是测试环境，可以跳过更改journal分区这一步骤\n\n#### 3.3.2 创建journal\n\n生成journal分区，一般选ssd盘作为journal分区，这里使用ssd的/dev/sdb1分区作为journal\n\n使用fdisk工分出磁盘/dev/sdb1,\n\n```shell\n#清除磁盘所有分区(重新添加时需要)\n#sgdisk --zap-all --clear --mbrtogpt /dev/sdb\n#生成分区/dev/sdb1的uuid\n#uuidgen\n#b3897364-8807-48eb-9905-e2c8400d0cd4\n#创建分区\n#1:0:+100G 表示创建第一个分区，100G大小\n#sudo sgdisk --new=1:0:+100G --change-name=1:'ceph journal' --partition-guid=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --typecode=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --mbrtogpt -- /dev/vdf\n#格式化\nsudo mkfs.xfs /dev/sdb1\nsudo rm -f /var/lib/ceph/osd/ceph-4/journal \n#查看分区对应的partuuid， 找出/dev/sdb1对应的partuuid\nsudo blkid\nsudo ln -s /dev/disk/by-partuuid/b3897364-8807-48eb-9905-e2c8400d0cd4 /var/lib/ceph/osd/ceph-0/journal\n\nsudo chown ceph:ceph -R /var/lib/ceph/osd/ceph-0\nsudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal\n#初始化新的journal\nsudo ceph-osd --mkjournal -i 0\nsudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal\n```\n\n\n\n#### 3.3.3 注册osd.{id}，id为osd编号，默认从0开始\n\n```shell\n# sudo ceph auth add osd.{id} osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-{id}/keyring\nsudo ceph auth add osd.0 osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-0/keyring\n#ceph auth list 中出现osd.0\n```\n\n#### 3.3.4 加入crush map\n\n这是m1上新创建的第一个osd，CRUSH map中还没有m1节点，因此首先要把m1节点加入CRUSH map，同理，m2/m3节点也需要加入CRUSH map\n\n```shell\n#ceph osd crush add-bucket {hostname} host\nsudo ceph osd crush add-bucket `hostname` host\n```\n\n然后把三个节点移动到默认的root `default`下面\n\n```shell\nsudo ceph osd crush move `hostname` root=default\n```\n\n添加osd.0到CRUSH map中的m1节点下面，加入后，osd.0就能够接收数据\n\n```shell\n#ceph osd crush add osd.{id} 0.4 root=sata rack=sata-rack01 host=sata-node5\nsudo ceph osd crush add osd.4 1.7 root=default host=`hostname`\n#0.4为此osd在CRUSH map中的权重值，它表示数据落在此osd上的比重，是一个相对值，一般按照1T磁盘比重值为1来计算，这里的osd数据盘1.7，所以值为1.7  \n```\n\n此时osd.0状态是`down`且`in`，`in`表示此osd位于CRUSH map，已经准备好接受数据，`down`表示osd进程运行异常，因为我们还没有启动osd.0进程\n\n#### 3.3.5 启动ceph-osd进程\n\n需要向systemctl传递osd的`id`以启动指定的osd进程，如下，我们准备启动osd.0进程\n\n```shell\n#systemctl start ceph-osd@{id}  id表示osd编号，从数字0开始\nsudo cp /usr/lib/systemd/system/ceph-osd@.service /usr/lib/systemd/system/ceph-osd@0.service\nsudo systemctl start ceph-osd@0\nsudo systemctl enable ceph-osd@0\n#sudo ceph-osd -i 0\n```\n\n上面就是添加osd.0的步骤，然后可以接着在其他`hostname`节点上添加osd.{1,2}，添加了这3个osd后，可以查看集群状态 ceph -s。\n\n### 3.4 搭建MDS\n\n创建目录：\n\n```shell\nsudo mkdir /var/lib/ceph/mds/ceph-`hostname`\nsudo chown ceph:ceph -R /var/lib/ceph/mds/ceph-`hostname`\n```\n\n在ceph.conf中添加如下信息：\n\n```shell\n[mds.{id}]\nhost = {id}\n例如：\n[mds.0]\nhost = 0\n```\n\n启动mds\n\n```shell\n#ceph-mds --cluster {cluster-name} -i {id} -m {mon-hostname}:{mon-port} [-f]\nsudo cp /usr/lib/systemd/system/ceph-mds@.service /usr/lib/systemd/system/ceph-mds@`hostname`.service \nsudo systemctl start ceph-mds@`hostname`\nsudo systemctl enable ceph-mds@`hostname`\n#ceph-mds --cluster ceph -i 0 -m e15p13447.ew9:6789\n```\n\n查看mds状态\n\n```shell\nceph mds stat\ncephfs-1/1/1 up  {0=1=up:active}, 2 up:standby\n```\n\n至此ceph集群搭建完成。","source":"_posts/manual-deploy-ceph.md","raw":"---\ntitle: 手动部署ceph集群\ntags: ceph\ncategories:\n  - ceph\nabbrlink: c3d7e91e\ndate: 2018-11-15 15:54:19\n---\n\n## 1、机器选择\n\n### 1.1 系统要求\n\nceph 最新 LTS 版本 (luminous) 推荐 linux 内核版本 `4.1.4` 及以上, 最低版本要求 `3.10.*`。\n\n\n### 1.2 服务器\n\n这里选择三台服务器来部署ceph集群，一台Mon+五台OSD\n\n------\n\n| 节点            | 服务             | cluster network  | public network   |\n| --------------- | ---------------- | ---------------- | ---------------- |\n| 192.168.226.20  | osd.1,mon.node2  | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.21  | osd.4            | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.22  | osd.2, mon.node1 | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.96  | osd.3,mon.node3  | 192.168.226.0/24 | 192.168.226.0/24 |\n| 192.168.226.106 | osd.0            | 192.168.226.0/24 | 192.168.226.0/24 |\n\n每个节点只能使用1块磁盘部署osd。所以，集群共有5个`osd`进程，3个`monitor`进程。\n\ncluster network 是处理osd间的数据复制，数据重平衡，osd进程心跳检测的网络，其不对外提供服务，只在各个osd节点间通信，本文使用eth1网卡作为cluster network，三个节点网卡eth1桥接到同一个网桥br1上\n\n\n\n## 2、环境配置 \n\n配置每个节点的host文件，在 `/etc/hosts`文件中添加如下内容：\n\n```shell\n192.168.226.20 ceph-1\n192.168.226.22 ceph-2\n192.168.226.96 ceph-3\n```\n\n### 2.2 ceph节点安装\n\n你的管理节点必须能够通过 SSH 无密码地访问各 Ceph 节点。如果 `ceph-deploy` 以某个普通用户登录，那么这个用户必须有无密码使用 `sudo` 的权限。\n\n#### 2.2.1 安装 NTP\n\n我们建议在所有 Ceph 节点上安装 NTP 服务（特别是 Ceph Monitor 节点），以免因时钟漂移导致故障，详情见[时钟](http://docs.ceph.org.cn/rados/configuration/mon-config-ref#clock)。\n\n```shell\nsudo yum install ntp ntpdate ntp-doc\n```\n\n确保在各 Ceph 节点上启动了 NTP 服务，并且要使用同一个 NTP 服务器，详情见 [NTP](http://www.ntp.org/) 。\n\n#### 2.2.2 安装 SSH 服务器\n\n在**所有 Ceph** 节点上执行如下步骤：\n\n1. 在各 Ceph 节点安装 SSH 服务器（如果还没有）\n\n   ```shell\n   sudo yum install openssh-server\n   ```\n\n2. 确保**所有** Ceph 节点上的 SSH 服务器都在运行。\n\n#### 2.2.3 安装ceph\n\n由于蚂蚁内部物理机不能访问外网，使用以下步骤安装ceph。\n\n在**所有Ceph**节点上执行如下步骤：\n\n下载ceph所有的依赖rpm，并解压缩\n\n```shell\nsudo wget http://qianli-lzh.oss-cn-hangzhou-zmf.aliyuncs.com/bill_inference_public%2Fceph.tar\nsudo tar -xvf bill_inference_public%2Fceph.tar\n```\n\n手动安装所有的rpm\n\n```shell\nsudo rpm -ivh --force --nodeps ceph/*.rpm\n```\n\n验证ceph是否正确安装\n\n```shell\nceph -v\nceph version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)\n```\n\n#### 2.2.4 关闭防火墙\n\n```shell\nsudo sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config\nsudo setenforce 0\nsudo systemctl stop firewalld \nsudo systemctl disable firewalld\n```\n\n## 3、集群搭建\n\n### 3.1 搭建Mon集群 (使用admin账户)\n\n**创建配置文件**\n\n在**每台节点机器**上创建配置文件`/etc/ceph/ceph.conf`：\n\n```shell\n[global]\nfsid = 932XXXXX-fba7-XXXX-9526-a858c613f468\nmon initial members = e15p13447.ew9\nmon host = 192.168.226.20,192.168.226.22,192.168.226.96\nrbd default features = 1\nauth_cluster_required = none\nauth_service_required = none\nauth_client_required = none\npublic network = 192.168.226.0/24\ncluster network = 192.168.226.0/24\nosd journal size = 1024\nosd pool default size = 2\nosd pool default min size = 1\nosd pool default pg num = 128\nosd pool default pgp num = 128\nosd crush chooseleaf type = 1\nmon_max_pg_per_osd = 200\n\n[mds.ceph-1]\nhost = ceph-1\n[mds.ceph-2]\nhost = ceph-2\n[mds.ceph-3]\nhost = ceph-3\n\n[mon]\nmon allow pool delete = true\n```\n\n其中 `fsid` 是为集群分配的一个 uuid, 初始化 mon 节点其实只需要这一个配置就够了。\n`mon host` 配置 ceph 命令行工具访问操作 ceph 集群时查找 mon 节点入口。\nceph 集群可包含多个 mon 节点实现高可用容灾, 避免单点故障。\n`rbd default features = 1` 配置 rbd 客户端创建磁盘时禁用一些需要高版本内核才能支持的特性。\n\n#### 3.1.2 主mon节点 （192.168.226.20）\n\n1、为此集群创建密钥环、并生成Monitor密钥 (3台机器一样)\n\n```shell\nsudo ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'\n```\n\n2、生成管理员密钥环，生成 `client.admin` 用户并加入密钥环 (3台机器一样)\n\n```shell\nsudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *' \n```\n\n3、把 `client.admin` 密钥加入 `ceph.mon.keyring`  (3台机器一样)\n\n```shell\nsudo ceph-authtool /tmp/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring\n```\n\n4、用规划好的主机名、对应 IP 地址、和 FSID 生成一个Monitor Map，并保存为 `/tmp/monmap`\n\n```shell\nhost_name=`hostname`\nsudo monmaptool --create --add $host_name 192.168.226.20  --fsid 932XXXXX-fba7-XXXX-9526-a858c613f468 /tmp/monmap --clobber\n```\n\n5、在Monitor主机上分别创建数据目录\n\n```shell\nhost_name=`hostname`\n#在admin账户下\nsudo mkdir /var/lib/ceph/mon/ceph-$host_name/\n```\n\n6、用Monitor Map和密钥环组装守护进程所需的初始数据\n\n```shell\nsudo ceph-mon --mkfs -i $host_name --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring\n```\n\n7、建一个空文件 `done` ，表示监视器已创建、可以启动了\n\n```shell\nsudo touch /var/lib/ceph/mon/ceph-$host_name/done\n```\n\n8、启动Monitor\n\n```shell\n#sudo ceph-mon -f --cluster ceph --id $host_name &\nsudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service\nsudo systemctl start ceph-mon@$host_name\nsudo systemctl enable ceph-mon@$host_name\n```\n\n9、确认下集群在运行\n\n```shell\nceph -s\n```\n\n事例：\n\n```shell\n  cluster:\n    id:     932XXXXX-fba7-XXXX-9526-a858c613f468\n    health: HEALTH_OK\n \n  services:\n    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3\n    mgr: no daemons active\n    osd: 0 osds: 0 up, 0 in\n \n  data:\n    pools:   0 pools, 0 pgs\n    objects: 0 objects, 0B\n    usage:   0B used, 0B / 0B avail\n    pgs:     \n```\n\n#### 3.1.2 从mon节点 (192.168.226.22 & 192.168.226.96)\n\n```shell\nhost_name=`hostname`\nsudo ceph mon getmap -o /tmp/monmap\nsudo rm -rf /var/lib/ceph/mon/ceph-$host_name\nsudo ceph-mon -i $host_name --mkfs --monmap /tmp/monmap\nsudo chown -R ceph:ceph /var/lib/ceph/mon/ceph-$host_name/\n#nohup ceph-mon -f --cluster ceph --id $host_name --setuser ceph --setgroup ceph &\n#ceph-mon -f --cluster ceph --id $host_name &\nsudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service\nsudo systemctl start ceph-mon@$host_name\nsudo systemctl enable ceph-mon@$host_name\n```\n\n\n\n### 3.2 创建ceph-mgr\n\n#### 3.2.1 创建用户 openstack 用于 MGR 监控\n\n```shell\nceph auth get-or-create mgr.openstack mon 'allow *' osd 'allow *' mds 'allow *'\n输出：\n[mgr.openstack]\n        key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxugvXkLfgauLA==\n```\n\n需要将之前创建的用户密码存放至对应位置\n\n```shell\nmkdir /var/lib/ceph/mgr/ceph-openstack\nceph auth get mgr.openstack -o  /var/lib/ceph/mgr/ceph-openstack/keyring\nexported keyring for mgr.openstack\n```\n\n#### 3.2.2 启动mgr\n\n```shell\nceph-mgr -i openstack\n```\n\n监控状态\n\n```shell\n$ceph -s\n  cluster:\n    id:     932e88a6-fba7-45a9-9526-a858c613f468\n    health: HEALTH_OK\n \n  services:\n    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3\n    mgr: openstack(active)\n    mds: cephfs-1/1/1 up  {0=2=up:active}, 2 up:standby\n    osd: 3 osds: 3 up, 3 in\n \n  data:\n    pools:   2 pools, 256 pgs\n    objects: 21 objects, 3.04KiB\n    usage:   3.32GiB used, 1.17TiB / 1.17TiB avail\n    pgs:     256 active+clean\n```\n\n当 mgr 服务被激活之后, service 中 mgr 会显示 mgr-$name(active) \ndata 部分信息将变得可用\n\n### 3.3 手动搭建osd集群(三台机器上做相同的操作，注意osd_id的变化)\n\n添加一个新osd，`id`可以省略，ceph会自动使用最小可用整数，第一个osd从0开始\n\n```shell\n#ceph osd create {id}\nceph osd create\n0\n```\n\n#### 3.3.1 初始化osd目录\n\n创建osd.0目录，目录名格式`{cluster-name}-{id}`\n\n```shell\n#mkdir /var/lib/ceph/osd/{cluster-name}-{id}\nsudo mkdir /var/lib/ceph/osd/ceph-0\n```\n\n挂载osd.0的数据盘/dev/sdb2\n\n```shell\nsudo mkfs.xfs /dev/sdb2\nsudo mount /dev/sdb2 /var/lib/ceph/osd/ceph-0\n```\n\n初始化osd数据目录\n\n```shell\n# sudo ceph-osd -i {id} --mkfs --mkkey\nsudo ceph-osd -i 0 --mkfs --mkkey\n#--mkkey要求osd数据目录为空\n#这会创建osd.0的keyring /var/lib/ceph/osd/ceph-0/keyring\n```\n\n初始化后，默认使用普通文件/var/lib/ceph/osd/ceph-3/journal作为osd.0的journal分区，普通文件作为journal分区性能不高，若只是测试环境，可以跳过更改journal分区这一步骤\n\n#### 3.3.2 创建journal\n\n生成journal分区，一般选ssd盘作为journal分区，这里使用ssd的/dev/sdb1分区作为journal\n\n使用fdisk工分出磁盘/dev/sdb1,\n\n```shell\n#清除磁盘所有分区(重新添加时需要)\n#sgdisk --zap-all --clear --mbrtogpt /dev/sdb\n#生成分区/dev/sdb1的uuid\n#uuidgen\n#b3897364-8807-48eb-9905-e2c8400d0cd4\n#创建分区\n#1:0:+100G 表示创建第一个分区，100G大小\n#sudo sgdisk --new=1:0:+100G --change-name=1:'ceph journal' --partition-guid=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --typecode=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --mbrtogpt -- /dev/vdf\n#格式化\nsudo mkfs.xfs /dev/sdb1\nsudo rm -f /var/lib/ceph/osd/ceph-4/journal \n#查看分区对应的partuuid， 找出/dev/sdb1对应的partuuid\nsudo blkid\nsudo ln -s /dev/disk/by-partuuid/b3897364-8807-48eb-9905-e2c8400d0cd4 /var/lib/ceph/osd/ceph-0/journal\n\nsudo chown ceph:ceph -R /var/lib/ceph/osd/ceph-0\nsudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal\n#初始化新的journal\nsudo ceph-osd --mkjournal -i 0\nsudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal\n```\n\n\n\n#### 3.3.3 注册osd.{id}，id为osd编号，默认从0开始\n\n```shell\n# sudo ceph auth add osd.{id} osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-{id}/keyring\nsudo ceph auth add osd.0 osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-0/keyring\n#ceph auth list 中出现osd.0\n```\n\n#### 3.3.4 加入crush map\n\n这是m1上新创建的第一个osd，CRUSH map中还没有m1节点，因此首先要把m1节点加入CRUSH map，同理，m2/m3节点也需要加入CRUSH map\n\n```shell\n#ceph osd crush add-bucket {hostname} host\nsudo ceph osd crush add-bucket `hostname` host\n```\n\n然后把三个节点移动到默认的root `default`下面\n\n```shell\nsudo ceph osd crush move `hostname` root=default\n```\n\n添加osd.0到CRUSH map中的m1节点下面，加入后，osd.0就能够接收数据\n\n```shell\n#ceph osd crush add osd.{id} 0.4 root=sata rack=sata-rack01 host=sata-node5\nsudo ceph osd crush add osd.4 1.7 root=default host=`hostname`\n#0.4为此osd在CRUSH map中的权重值，它表示数据落在此osd上的比重，是一个相对值，一般按照1T磁盘比重值为1来计算，这里的osd数据盘1.7，所以值为1.7  \n```\n\n此时osd.0状态是`down`且`in`，`in`表示此osd位于CRUSH map，已经准备好接受数据，`down`表示osd进程运行异常，因为我们还没有启动osd.0进程\n\n#### 3.3.5 启动ceph-osd进程\n\n需要向systemctl传递osd的`id`以启动指定的osd进程，如下，我们准备启动osd.0进程\n\n```shell\n#systemctl start ceph-osd@{id}  id表示osd编号，从数字0开始\nsudo cp /usr/lib/systemd/system/ceph-osd@.service /usr/lib/systemd/system/ceph-osd@0.service\nsudo systemctl start ceph-osd@0\nsudo systemctl enable ceph-osd@0\n#sudo ceph-osd -i 0\n```\n\n上面就是添加osd.0的步骤，然后可以接着在其他`hostname`节点上添加osd.{1,2}，添加了这3个osd后，可以查看集群状态 ceph -s。\n\n### 3.4 搭建MDS\n\n创建目录：\n\n```shell\nsudo mkdir /var/lib/ceph/mds/ceph-`hostname`\nsudo chown ceph:ceph -R /var/lib/ceph/mds/ceph-`hostname`\n```\n\n在ceph.conf中添加如下信息：\n\n```shell\n[mds.{id}]\nhost = {id}\n例如：\n[mds.0]\nhost = 0\n```\n\n启动mds\n\n```shell\n#ceph-mds --cluster {cluster-name} -i {id} -m {mon-hostname}:{mon-port} [-f]\nsudo cp /usr/lib/systemd/system/ceph-mds@.service /usr/lib/systemd/system/ceph-mds@`hostname`.service \nsudo systemctl start ceph-mds@`hostname`\nsudo systemctl enable ceph-mds@`hostname`\n#ceph-mds --cluster ceph -i 0 -m e15p13447.ew9:6789\n```\n\n查看mds状态\n\n```shell\nceph mds stat\ncephfs-1/1/1 up  {0=1=up:active}, 2 up:standby\n```\n\n至此ceph集群搭建完成。","slug":"manual-deploy-ceph","published":1,"updated":"2018-11-15T12:15:51.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjoimgt070003ppygtst2of76","content":"<h2 id=\"1、机器选择\"><a href=\"#1、机器选择\" class=\"headerlink\" title=\"1、机器选择\"></a>1、机器选择</h2><h3 id=\"1-1-系统要求\"><a href=\"#1-1-系统要求\" class=\"headerlink\" title=\"1.1 系统要求\"></a>1.1 系统要求</h3><p>ceph 最新 LTS 版本 (luminous) 推荐 linux 内核版本 <code>4.1.4</code> 及以上, 最低版本要求 <code>3.10.*</code>。</p>\n<h3 id=\"1-2-服务器\"><a href=\"#1-2-服务器\" class=\"headerlink\" title=\"1.2 服务器\"></a>1.2 服务器</h3><p>这里选择三台服务器来部署ceph集群，一台Mon+五台OSD</p>\n<hr>\n<table>\n<thead>\n<tr>\n<th>节点</th>\n<th>服务</th>\n<th>cluster network</th>\n<th>public network</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>192.168.226.20</td>\n<td>osd.1,mon.node2</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.21</td>\n<td>osd.4</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.22</td>\n<td>osd.2, mon.node1</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.96</td>\n<td>osd.3,mon.node3</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.106</td>\n<td>osd.0</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n</tbody>\n</table>\n<p>每个节点只能使用1块磁盘部署osd。所以，集群共有5个<code>osd</code>进程，3个<code>monitor</code>进程。</p>\n<p>cluster network 是处理osd间的数据复制，数据重平衡，osd进程心跳检测的网络，其不对外提供服务，只在各个osd节点间通信，本文使用eth1网卡作为cluster network，三个节点网卡eth1桥接到同一个网桥br1上</p>\n<h2 id=\"2、环境配置\"><a href=\"#2、环境配置\" class=\"headerlink\" title=\"2、环境配置\"></a>2、环境配置</h2><p>配置每个节点的host文件，在 <code>/etc/hosts</code>文件中添加如下内容：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">192.168.226.20 ceph-1</span><br><span class=\"line\">192.168.226.22 ceph-2</span><br><span class=\"line\">192.168.226.96 ceph-3</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-ceph节点安装\"><a href=\"#2-2-ceph节点安装\" class=\"headerlink\" title=\"2.2 ceph节点安装\"></a>2.2 ceph节点安装</h3><p>你的管理节点必须能够通过 SSH 无密码地访问各 Ceph 节点。如果 <code>ceph-deploy</code> 以某个普通用户登录，那么这个用户必须有无密码使用 <code>sudo</code> 的权限。</p>\n<h4 id=\"2-2-1-安装-NTP\"><a href=\"#2-2-1-安装-NTP\" class=\"headerlink\" title=\"2.2.1 安装 NTP\"></a>2.2.1 安装 NTP</h4><p>我们建议在所有 Ceph 节点上安装 NTP 服务（特别是 Ceph Monitor 节点），以免因时钟漂移导致故障，详情见<a href=\"http://docs.ceph.org.cn/rados/configuration/mon-config-ref#clock\" target=\"_blank\" rel=\"noopener\">时钟</a>。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum install ntp ntpdate ntp-doc</span><br></pre></td></tr></table></figure>\n<p>确保在各 Ceph 节点上启动了 NTP 服务，并且要使用同一个 NTP 服务器，详情见 <a href=\"http://www.ntp.org/\" target=\"_blank\" rel=\"noopener\">NTP</a> 。</p>\n<h4 id=\"2-2-2-安装-SSH-服务器\"><a href=\"#2-2-2-安装-SSH-服务器\" class=\"headerlink\" title=\"2.2.2 安装 SSH 服务器\"></a>2.2.2 安装 SSH 服务器</h4><p>在<strong>所有 Ceph</strong> 节点上执行如下步骤：</p>\n<ol>\n<li><p>在各 Ceph 节点安装 SSH 服务器（如果还没有）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum install openssh-server</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>确保<strong>所有</strong> Ceph 节点上的 SSH 服务器都在运行。</p>\n</li>\n</ol>\n<h4 id=\"2-2-3-安装ceph\"><a href=\"#2-2-3-安装ceph\" class=\"headerlink\" title=\"2.2.3 安装ceph\"></a>2.2.3 安装ceph</h4><p>由于蚂蚁内部物理机不能访问外网，使用以下步骤安装ceph。</p>\n<p>在<strong>所有Ceph</strong>节点上执行如下步骤：</p>\n<p>下载ceph所有的依赖rpm，并解压缩</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo wget http://qianli-lzh.oss-cn-hangzhou-zmf.aliyuncs.com/bill_inference_public%2Fceph.tar</span><br><span class=\"line\">sudo tar -xvf bill_inference_public%2Fceph.tar</span><br></pre></td></tr></table></figure>\n<p>手动安装所有的rpm</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rpm -ivh --force --nodeps ceph/*.rpm</span><br></pre></td></tr></table></figure>\n<p>验证ceph是否正确安装</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph -v</span><br><span class=\"line\">ceph version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-2-4-关闭防火墙\"><a href=\"#2-2-4-关闭防火墙\" class=\"headerlink\" title=\"2.2.4 关闭防火墙\"></a>2.2.4 关闭防火墙</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config</span><br><span class=\"line\">sudo setenforce 0</span><br><span class=\"line\">sudo systemctl stop firewalld </span><br><span class=\"line\">sudo systemctl disable firewalld</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、集群搭建\"><a href=\"#3、集群搭建\" class=\"headerlink\" title=\"3、集群搭建\"></a>3、集群搭建</h2><h3 id=\"3-1-搭建Mon集群-使用admin账户\"><a href=\"#3-1-搭建Mon集群-使用admin账户\" class=\"headerlink\" title=\"3.1 搭建Mon集群 (使用admin账户)\"></a>3.1 搭建Mon集群 (使用admin账户)</h3><p><strong>创建配置文件</strong></p>\n<p>在<strong>每台节点机器</strong>上创建配置文件<code>/etc/ceph/ceph.conf</code>：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[global]</span><br><span class=\"line\">fsid = 932XXXXX-fba7-XXXX-9526-a858c613f468</span><br><span class=\"line\">mon initial members = e15p13447.ew9</span><br><span class=\"line\">mon host = 192.168.226.20,192.168.226.22,192.168.226.96</span><br><span class=\"line\">rbd default features = 1</span><br><span class=\"line\">auth_cluster_required = none</span><br><span class=\"line\">auth_service_required = none</span><br><span class=\"line\">auth_client_required = none</span><br><span class=\"line\">public network = 192.168.226.0/24</span><br><span class=\"line\">cluster network = 192.168.226.0/24</span><br><span class=\"line\">osd journal size = 1024</span><br><span class=\"line\">osd pool default size = 2</span><br><span class=\"line\">osd pool default min size = 1</span><br><span class=\"line\">osd pool default pg num = 128</span><br><span class=\"line\">osd pool default pgp num = 128</span><br><span class=\"line\">osd crush chooseleaf type = 1</span><br><span class=\"line\">mon_max_pg_per_osd = 200</span><br><span class=\"line\"></span><br><span class=\"line\">[mds.ceph-1]</span><br><span class=\"line\">host = ceph-1</span><br><span class=\"line\">[mds.ceph-2]</span><br><span class=\"line\">host = ceph-2</span><br><span class=\"line\">[mds.ceph-3]</span><br><span class=\"line\">host = ceph-3</span><br><span class=\"line\"></span><br><span class=\"line\">[mon]</span><br><span class=\"line\">mon allow pool delete = true</span><br></pre></td></tr></table></figure>\n<p>其中 <code>fsid</code> 是为集群分配的一个 uuid, 初始化 mon 节点其实只需要这一个配置就够了。<br><code>mon host</code> 配置 ceph 命令行工具访问操作 ceph 集群时查找 mon 节点入口。<br>ceph 集群可包含多个 mon 节点实现高可用容灾, 避免单点故障。<br><code>rbd default features = 1</code> 配置 rbd 客户端创建磁盘时禁用一些需要高版本内核才能支持的特性。</p>\n<h4 id=\"3-1-2-主mon节点-（192-168-226-20）\"><a href=\"#3-1-2-主mon节点-（192-168-226-20）\" class=\"headerlink\" title=\"3.1.2 主mon节点 （192.168.226.20）\"></a>3.1.2 主mon节点 （192.168.226.20）</h4><p>1、为此集群创建密钥环、并生成Monitor密钥 (3台机器一样)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'</span><br></pre></td></tr></table></figure>\n<p>2、生成管理员密钥环，生成 <code>client.admin</code> 用户并加入密钥环 (3台机器一样)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *'</span><br></pre></td></tr></table></figure>\n<p>3、把 <code>client.admin</code> 密钥加入 <code>ceph.mon.keyring</code>  (3台机器一样)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-authtool /tmp/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring</span><br></pre></td></tr></table></figure>\n<p>4、用规划好的主机名、对应 IP 地址、和 FSID 生成一个Monitor Map，并保存为 <code>/tmp/monmap</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">host_name=`hostname`</span><br><span class=\"line\">sudo monmaptool --create --add $host_name 192.168.226.20  --fsid 932XXXXX-fba7-XXXX-9526-a858c613f468 /tmp/monmap --clobber</span><br></pre></td></tr></table></figure>\n<p>5、在Monitor主机上分别创建数据目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">host_name=`hostname`</span><br><span class=\"line\"><span class=\"meta\">#</span>在admin账户下</span><br><span class=\"line\">sudo mkdir /var/lib/ceph/mon/ceph-$host_name/</span><br></pre></td></tr></table></figure>\n<p>6、用Monitor Map和密钥环组装守护进程所需的初始数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-mon --mkfs -i $host_name --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring</span><br></pre></td></tr></table></figure>\n<p>7、建一个空文件 <code>done</code> ，表示监视器已创建、可以启动了</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo touch /var/lib/ceph/mon/ceph-$host_name/done</span><br></pre></td></tr></table></figure>\n<p>8、启动Monitor</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>sudo ceph-mon -f --cluster ceph --id $host_name &amp;</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service</span><br><span class=\"line\">sudo systemctl start ceph-mon@$host_name</span><br><span class=\"line\">sudo systemctl enable ceph-mon@$host_name</span><br></pre></td></tr></table></figure>\n<p>9、确认下集群在运行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph -s</span><br></pre></td></tr></table></figure>\n<p>事例：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cluster:</span><br><span class=\"line\">  id:     932XXXXX-fba7-XXXX-9526-a858c613f468</span><br><span class=\"line\">  health: HEALTH_OK</span><br><span class=\"line\"> </span><br><span class=\"line\">services:</span><br><span class=\"line\">  mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3</span><br><span class=\"line\">  mgr: no daemons active</span><br><span class=\"line\">  osd: 0 osds: 0 up, 0 in</span><br><span class=\"line\"> </span><br><span class=\"line\">data:</span><br><span class=\"line\">  pools:   0 pools, 0 pgs</span><br><span class=\"line\">  objects: 0 objects, 0B</span><br><span class=\"line\">  usage:   0B used, 0B / 0B avail</span><br><span class=\"line\">  pgs:</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-1-2-从mon节点-192-168-226-22-amp-192-168-226-96\"><a href=\"#3-1-2-从mon节点-192-168-226-22-amp-192-168-226-96\" class=\"headerlink\" title=\"3.1.2 从mon节点 (192.168.226.22 &amp; 192.168.226.96)\"></a>3.1.2 从mon节点 (192.168.226.22 &amp; 192.168.226.96)</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">host_name=`hostname`</span><br><span class=\"line\">sudo ceph mon getmap -o /tmp/monmap</span><br><span class=\"line\">sudo rm -rf /var/lib/ceph/mon/ceph-$host_name</span><br><span class=\"line\">sudo ceph-mon -i $host_name --mkfs --monmap /tmp/monmap</span><br><span class=\"line\">sudo chown -R ceph:ceph /var/lib/ceph/mon/ceph-$host_name/</span><br><span class=\"line\"><span class=\"meta\">#</span>nohup ceph-mon -f --cluster ceph --id $host_name --setuser ceph --setgroup ceph &amp;</span><br><span class=\"line\"><span class=\"meta\">#</span>ceph-mon -f --cluster ceph --id $host_name &amp;</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service</span><br><span class=\"line\">sudo systemctl start ceph-mon@$host_name</span><br><span class=\"line\">sudo systemctl enable ceph-mon@$host_name</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-创建ceph-mgr\"><a href=\"#3-2-创建ceph-mgr\" class=\"headerlink\" title=\"3.2 创建ceph-mgr\"></a>3.2 创建ceph-mgr</h3><h4 id=\"3-2-1-创建用户-openstack-用于-MGR-监控\"><a href=\"#3-2-1-创建用户-openstack-用于-MGR-监控\" class=\"headerlink\" title=\"3.2.1 创建用户 openstack 用于 MGR 监控\"></a>3.2.1 创建用户 openstack 用于 MGR 监控</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph auth get-or-create mgr.openstack mon 'allow *' osd 'allow *' mds 'allow *'</span><br><span class=\"line\">输出：</span><br><span class=\"line\">[mgr.openstack]</span><br><span class=\"line\">        key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxugvXkLfgauLA==</span><br></pre></td></tr></table></figure>\n<p>需要将之前创建的用户密码存放至对应位置</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir /var/lib/ceph/mgr/ceph-openstack</span><br><span class=\"line\">ceph auth get mgr.openstack -o  /var/lib/ceph/mgr/ceph-openstack/keyring</span><br><span class=\"line\">exported keyring for mgr.openstack</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-2-2-启动mgr\"><a href=\"#3-2-2-启动mgr\" class=\"headerlink\" title=\"3.2.2 启动mgr\"></a>3.2.2 启动mgr</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-mgr -i openstack</span><br></pre></td></tr></table></figure>\n<p>监控状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span>ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     932e88a6-fba7-45a9-9526-a858c613f468</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"> </span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3</span><br><span class=\"line\">    mgr: openstack(active)</span><br><span class=\"line\">    mds: cephfs-1/1/1 up  &#123;0=2=up:active&#125;, 2 up:standby</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\"> </span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   2 pools, 256 pgs</span><br><span class=\"line\">    objects: 21 objects, 3.04KiB</span><br><span class=\"line\">    usage:   3.32GiB used, 1.17TiB / 1.17TiB avail</span><br><span class=\"line\">    pgs:     256 active+clean</span><br></pre></td></tr></table></figure>\n<p>当 mgr 服务被激活之后, service 中 mgr 会显示 mgr-$name(active)<br>data 部分信息将变得可用</p>\n<h3 id=\"3-3-手动搭建osd集群-三台机器上做相同的操作，注意osd-id的变化\"><a href=\"#3-3-手动搭建osd集群-三台机器上做相同的操作，注意osd-id的变化\" class=\"headerlink\" title=\"3.3 手动搭建osd集群(三台机器上做相同的操作，注意osd_id的变化)\"></a>3.3 手动搭建osd集群(三台机器上做相同的操作，注意osd_id的变化)</h3><p>添加一个新osd，<code>id</code>可以省略，ceph会自动使用最小可用整数，第一个osd从0开始</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph osd create &#123;id&#125;</span><br><span class=\"line\">ceph osd create</span><br><span class=\"line\">0</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3-1-初始化osd目录\"><a href=\"#3-3-1-初始化osd目录\" class=\"headerlink\" title=\"3.3.1 初始化osd目录\"></a>3.3.1 初始化osd目录</h4><p>创建osd.0目录，目录名格式<code>{cluster-name}-{id}</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>mkdir /var/lib/ceph/osd/&#123;cluster-name&#125;-&#123;id&#125;</span><br><span class=\"line\">sudo mkdir /var/lib/ceph/osd/ceph-0</span><br></pre></td></tr></table></figure>\n<p>挂载osd.0的数据盘/dev/sdb2</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkfs.xfs /dev/sdb2</span><br><span class=\"line\">sudo mount /dev/sdb2 /var/lib/ceph/osd/ceph-0</span><br></pre></td></tr></table></figure>\n<p>初始化osd数据目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> sudo ceph-osd -i &#123;id&#125; --mkfs --mkkey</span><br><span class=\"line\">sudo ceph-osd -i 0 --mkfs --mkkey</span><br><span class=\"line\"><span class=\"meta\">#</span>--mkkey要求osd数据目录为空</span><br><span class=\"line\"><span class=\"meta\">#</span>这会创建osd.0的keyring /var/lib/ceph/osd/ceph-0/keyring</span><br></pre></td></tr></table></figure>\n<p>初始化后，默认使用普通文件/var/lib/ceph/osd/ceph-3/journal作为osd.0的journal分区，普通文件作为journal分区性能不高，若只是测试环境，可以跳过更改journal分区这一步骤</p>\n<h4 id=\"3-3-2-创建journal\"><a href=\"#3-3-2-创建journal\" class=\"headerlink\" title=\"3.3.2 创建journal\"></a>3.3.2 创建journal</h4><p>生成journal分区，一般选ssd盘作为journal分区，这里使用ssd的/dev/sdb1分区作为journal</p>\n<p>使用fdisk工分出磁盘/dev/sdb1,</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>清除磁盘所有分区(重新添加时需要)</span><br><span class=\"line\"><span class=\"meta\">#</span>sgdisk --zap-all --clear --mbrtogpt /dev/sdb</span><br><span class=\"line\"><span class=\"meta\">#</span>生成分区/dev/sdb1的uuid</span><br><span class=\"line\"><span class=\"meta\">#</span>uuidgen</span><br><span class=\"line\"><span class=\"meta\">#</span>b3897364-8807-48eb-9905-e2c8400d0cd4</span><br><span class=\"line\"><span class=\"meta\">#</span>创建分区</span><br><span class=\"line\"><span class=\"meta\">#</span>1:0:+100G 表示创建第一个分区，100G大小</span><br><span class=\"line\"><span class=\"meta\">#</span>sudo sgdisk --new=1:0:+100G --change-name=1:'ceph journal' --partition-guid=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --typecode=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --mbrtogpt -- /dev/vdf</span><br><span class=\"line\"><span class=\"meta\">#</span>格式化</span><br><span class=\"line\">sudo mkfs.xfs /dev/sdb1</span><br><span class=\"line\">sudo rm -f /var/lib/ceph/osd/ceph-4/journal </span><br><span class=\"line\"><span class=\"meta\">#</span>查看分区对应的partuuid， 找出/dev/sdb1对应的partuuid</span><br><span class=\"line\">sudo blkid</span><br><span class=\"line\">sudo ln -s /dev/disk/by-partuuid/b3897364-8807-48eb-9905-e2c8400d0cd4 /var/lib/ceph/osd/ceph-0/journal</span><br><span class=\"line\"></span><br><span class=\"line\">sudo chown ceph:ceph -R /var/lib/ceph/osd/ceph-0</span><br><span class=\"line\">sudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal</span><br><span class=\"line\"><span class=\"meta\">#</span>初始化新的journal</span><br><span class=\"line\">sudo ceph-osd --mkjournal -i 0</span><br><span class=\"line\">sudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3-3-注册osd-id-，id为osd编号，默认从0开始\"><a href=\"#3-3-3-注册osd-id-，id为osd编号，默认从0开始\" class=\"headerlink\" title=\"3.3.3 注册osd.{id}，id为osd编号，默认从0开始\"></a>3.3.3 注册osd.{id}，id为osd编号，默认从0开始</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> sudo ceph auth add osd.&#123;id&#125; osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-&#123;id&#125;/keyring</span><br><span class=\"line\">sudo ceph auth add osd.0 osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-0/keyring</span><br><span class=\"line\"><span class=\"meta\">#</span>ceph auth list 中出现osd.0</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3-4-加入crush-map\"><a href=\"#3-3-4-加入crush-map\" class=\"headerlink\" title=\"3.3.4 加入crush map\"></a>3.3.4 加入crush map</h4><p>这是m1上新创建的第一个osd，CRUSH map中还没有m1节点，因此首先要把m1节点加入CRUSH map，同理，m2/m3节点也需要加入CRUSH map</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph osd crush add-bucket &#123;hostname&#125; host</span><br><span class=\"line\">sudo ceph osd crush add-bucket `hostname` host</span><br></pre></td></tr></table></figure>\n<p>然后把三个节点移动到默认的root <code>default</code>下面</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph osd crush move `hostname` root=default</span><br></pre></td></tr></table></figure>\n<p>添加osd.0到CRUSH map中的m1节点下面，加入后，osd.0就能够接收数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph osd crush add osd.&#123;id&#125; 0.4 root=sata rack=sata-rack01 host=sata-node5</span><br><span class=\"line\">sudo ceph osd crush add osd.4 1.7 root=default host=`hostname`</span><br><span class=\"line\"><span class=\"meta\">#</span>0.4为此osd在CRUSH map中的权重值，它表示数据落在此osd上的比重，是一个相对值，一般按照1T磁盘比重值为1来计算，这里的osd数据盘1.7，所以值为1.7</span><br></pre></td></tr></table></figure>\n<p>此时osd.0状态是<code>down</code>且<code>in</code>，<code>in</code>表示此osd位于CRUSH map，已经准备好接受数据，<code>down</code>表示osd进程运行异常，因为我们还没有启动osd.0进程</p>\n<h4 id=\"3-3-5-启动ceph-osd进程\"><a href=\"#3-3-5-启动ceph-osd进程\" class=\"headerlink\" title=\"3.3.5 启动ceph-osd进程\"></a>3.3.5 启动ceph-osd进程</h4><p>需要向systemctl传递osd的<code>id</code>以启动指定的osd进程，如下，我们准备启动osd.0进程</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>systemctl start ceph-osd@&#123;id&#125;  id表示osd编号，从数字0开始</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-osd@.service /usr/lib/systemd/system/ceph-osd@0.service</span><br><span class=\"line\">sudo systemctl start ceph-osd@0</span><br><span class=\"line\">sudo systemctl enable ceph-osd@0</span><br><span class=\"line\"><span class=\"meta\">#</span>sudo ceph-osd -i 0</span><br></pre></td></tr></table></figure>\n<p>上面就是添加osd.0的步骤，然后可以接着在其他<code>hostname</code>节点上添加osd.{1,2}，添加了这3个osd后，可以查看集群状态 ceph -s。</p>\n<h3 id=\"3-4-搭建MDS\"><a href=\"#3-4-搭建MDS\" class=\"headerlink\" title=\"3.4 搭建MDS\"></a>3.4 搭建MDS</h3><p>创建目录：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir /var/lib/ceph/mds/ceph-`hostname`</span><br><span class=\"line\">sudo chown ceph:ceph -R /var/lib/ceph/mds/ceph-`hostname`</span><br></pre></td></tr></table></figure>\n<p>在ceph.conf中添加如下信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[mds.&#123;id&#125;]</span><br><span class=\"line\">host = &#123;id&#125;</span><br><span class=\"line\">例如：</span><br><span class=\"line\">[mds.0]</span><br><span class=\"line\">host = 0</span><br></pre></td></tr></table></figure>\n<p>启动mds</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph-mds --cluster &#123;cluster-name&#125; -i &#123;id&#125; -m &#123;mon-hostname&#125;:&#123;mon-port&#125; [-f]</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-mds@.service /usr/lib/systemd/system/ceph-mds@`hostname`.service </span><br><span class=\"line\">sudo systemctl start ceph-mds@`hostname`</span><br><span class=\"line\">sudo systemctl enable ceph-mds@`hostname`</span><br><span class=\"line\"><span class=\"meta\">#</span>ceph-mds --cluster ceph -i 0 -m e15p13447.ew9:6789</span><br></pre></td></tr></table></figure>\n<p>查看mds状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph mds stat</span><br><span class=\"line\">cephfs-1/1/1 up  &#123;0=1=up:active&#125;, 2 up:standby</span><br></pre></td></tr></table></figure>\n<p>至此ceph集群搭建完成。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1、机器选择\"><a href=\"#1、机器选择\" class=\"headerlink\" title=\"1、机器选择\"></a>1、机器选择</h2><h3 id=\"1-1-系统要求\"><a href=\"#1-1-系统要求\" class=\"headerlink\" title=\"1.1 系统要求\"></a>1.1 系统要求</h3><p>ceph 最新 LTS 版本 (luminous) 推荐 linux 内核版本 <code>4.1.4</code> 及以上, 最低版本要求 <code>3.10.*</code>。</p>\n<h3 id=\"1-2-服务器\"><a href=\"#1-2-服务器\" class=\"headerlink\" title=\"1.2 服务器\"></a>1.2 服务器</h3><p>这里选择三台服务器来部署ceph集群，一台Mon+五台OSD</p>\n<hr>\n<table>\n<thead>\n<tr>\n<th>节点</th>\n<th>服务</th>\n<th>cluster network</th>\n<th>public network</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>192.168.226.20</td>\n<td>osd.1,mon.node2</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.21</td>\n<td>osd.4</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.22</td>\n<td>osd.2, mon.node1</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.96</td>\n<td>osd.3,mon.node3</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n<tr>\n<td>192.168.226.106</td>\n<td>osd.0</td>\n<td>192.168.226.0/24</td>\n<td>192.168.226.0/24</td>\n</tr>\n</tbody>\n</table>\n<p>每个节点只能使用1块磁盘部署osd。所以，集群共有5个<code>osd</code>进程，3个<code>monitor</code>进程。</p>\n<p>cluster network 是处理osd间的数据复制，数据重平衡，osd进程心跳检测的网络，其不对外提供服务，只在各个osd节点间通信，本文使用eth1网卡作为cluster network，三个节点网卡eth1桥接到同一个网桥br1上</p>\n<h2 id=\"2、环境配置\"><a href=\"#2、环境配置\" class=\"headerlink\" title=\"2、环境配置\"></a>2、环境配置</h2><p>配置每个节点的host文件，在 <code>/etc/hosts</code>文件中添加如下内容：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">192.168.226.20 ceph-1</span><br><span class=\"line\">192.168.226.22 ceph-2</span><br><span class=\"line\">192.168.226.96 ceph-3</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-2-ceph节点安装\"><a href=\"#2-2-ceph节点安装\" class=\"headerlink\" title=\"2.2 ceph节点安装\"></a>2.2 ceph节点安装</h3><p>你的管理节点必须能够通过 SSH 无密码地访问各 Ceph 节点。如果 <code>ceph-deploy</code> 以某个普通用户登录，那么这个用户必须有无密码使用 <code>sudo</code> 的权限。</p>\n<h4 id=\"2-2-1-安装-NTP\"><a href=\"#2-2-1-安装-NTP\" class=\"headerlink\" title=\"2.2.1 安装 NTP\"></a>2.2.1 安装 NTP</h4><p>我们建议在所有 Ceph 节点上安装 NTP 服务（特别是 Ceph Monitor 节点），以免因时钟漂移导致故障，详情见<a href=\"http://docs.ceph.org.cn/rados/configuration/mon-config-ref#clock\" target=\"_blank\" rel=\"noopener\">时钟</a>。</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum install ntp ntpdate ntp-doc</span><br></pre></td></tr></table></figure>\n<p>确保在各 Ceph 节点上启动了 NTP 服务，并且要使用同一个 NTP 服务器，详情见 <a href=\"http://www.ntp.org/\" target=\"_blank\" rel=\"noopener\">NTP</a> 。</p>\n<h4 id=\"2-2-2-安装-SSH-服务器\"><a href=\"#2-2-2-安装-SSH-服务器\" class=\"headerlink\" title=\"2.2.2 安装 SSH 服务器\"></a>2.2.2 安装 SSH 服务器</h4><p>在<strong>所有 Ceph</strong> 节点上执行如下步骤：</p>\n<ol>\n<li><p>在各 Ceph 节点安装 SSH 服务器（如果还没有）</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo yum install openssh-server</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>确保<strong>所有</strong> Ceph 节点上的 SSH 服务器都在运行。</p>\n</li>\n</ol>\n<h4 id=\"2-2-3-安装ceph\"><a href=\"#2-2-3-安装ceph\" class=\"headerlink\" title=\"2.2.3 安装ceph\"></a>2.2.3 安装ceph</h4><p>由于蚂蚁内部物理机不能访问外网，使用以下步骤安装ceph。</p>\n<p>在<strong>所有Ceph</strong>节点上执行如下步骤：</p>\n<p>下载ceph所有的依赖rpm，并解压缩</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo wget http://qianli-lzh.oss-cn-hangzhou-zmf.aliyuncs.com/bill_inference_public%2Fceph.tar</span><br><span class=\"line\">sudo tar -xvf bill_inference_public%2Fceph.tar</span><br></pre></td></tr></table></figure>\n<p>手动安装所有的rpm</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo rpm -ivh --force --nodeps ceph/*.rpm</span><br></pre></td></tr></table></figure>\n<p>验证ceph是否正确安装</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph -v</span><br><span class=\"line\">ceph version 12.2.8 (ae699615bac534ea496ee965ac6192cb7e0e07c0) luminous (stable)</span><br></pre></td></tr></table></figure>\n<h4 id=\"2-2-4-关闭防火墙\"><a href=\"#2-2-4-关闭防火墙\" class=\"headerlink\" title=\"2.2.4 关闭防火墙\"></a>2.2.4 关闭防火墙</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config</span><br><span class=\"line\">sudo setenforce 0</span><br><span class=\"line\">sudo systemctl stop firewalld </span><br><span class=\"line\">sudo systemctl disable firewalld</span><br></pre></td></tr></table></figure>\n<h2 id=\"3、集群搭建\"><a href=\"#3、集群搭建\" class=\"headerlink\" title=\"3、集群搭建\"></a>3、集群搭建</h2><h3 id=\"3-1-搭建Mon集群-使用admin账户\"><a href=\"#3-1-搭建Mon集群-使用admin账户\" class=\"headerlink\" title=\"3.1 搭建Mon集群 (使用admin账户)\"></a>3.1 搭建Mon集群 (使用admin账户)</h3><p><strong>创建配置文件</strong></p>\n<p>在<strong>每台节点机器</strong>上创建配置文件<code>/etc/ceph/ceph.conf</code>：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[global]</span><br><span class=\"line\">fsid = 932XXXXX-fba7-XXXX-9526-a858c613f468</span><br><span class=\"line\">mon initial members = e15p13447.ew9</span><br><span class=\"line\">mon host = 192.168.226.20,192.168.226.22,192.168.226.96</span><br><span class=\"line\">rbd default features = 1</span><br><span class=\"line\">auth_cluster_required = none</span><br><span class=\"line\">auth_service_required = none</span><br><span class=\"line\">auth_client_required = none</span><br><span class=\"line\">public network = 192.168.226.0/24</span><br><span class=\"line\">cluster network = 192.168.226.0/24</span><br><span class=\"line\">osd journal size = 1024</span><br><span class=\"line\">osd pool default size = 2</span><br><span class=\"line\">osd pool default min size = 1</span><br><span class=\"line\">osd pool default pg num = 128</span><br><span class=\"line\">osd pool default pgp num = 128</span><br><span class=\"line\">osd crush chooseleaf type = 1</span><br><span class=\"line\">mon_max_pg_per_osd = 200</span><br><span class=\"line\"></span><br><span class=\"line\">[mds.ceph-1]</span><br><span class=\"line\">host = ceph-1</span><br><span class=\"line\">[mds.ceph-2]</span><br><span class=\"line\">host = ceph-2</span><br><span class=\"line\">[mds.ceph-3]</span><br><span class=\"line\">host = ceph-3</span><br><span class=\"line\"></span><br><span class=\"line\">[mon]</span><br><span class=\"line\">mon allow pool delete = true</span><br></pre></td></tr></table></figure>\n<p>其中 <code>fsid</code> 是为集群分配的一个 uuid, 初始化 mon 节点其实只需要这一个配置就够了。<br><code>mon host</code> 配置 ceph 命令行工具访问操作 ceph 集群时查找 mon 节点入口。<br>ceph 集群可包含多个 mon 节点实现高可用容灾, 避免单点故障。<br><code>rbd default features = 1</code> 配置 rbd 客户端创建磁盘时禁用一些需要高版本内核才能支持的特性。</p>\n<h4 id=\"3-1-2-主mon节点-（192-168-226-20）\"><a href=\"#3-1-2-主mon节点-（192-168-226-20）\" class=\"headerlink\" title=\"3.1.2 主mon节点 （192.168.226.20）\"></a>3.1.2 主mon节点 （192.168.226.20）</h4><p>1、为此集群创建密钥环、并生成Monitor密钥 (3台机器一样)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-authtool --create-keyring /tmp/ceph.mon.keyring --gen-key -n mon. --cap mon 'allow *'</span><br></pre></td></tr></table></figure>\n<p>2、生成管理员密钥环，生成 <code>client.admin</code> 用户并加入密钥环 (3台机器一样)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-authtool --create-keyring /etc/ceph/ceph.client.admin.keyring --gen-key -n client.admin --set-uid=0 --cap mon 'allow *' --cap osd 'allow *' --cap mds 'allow *' --cap mgr 'allow *'</span><br></pre></td></tr></table></figure>\n<p>3、把 <code>client.admin</code> 密钥加入 <code>ceph.mon.keyring</code>  (3台机器一样)</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-authtool /tmp/ceph.mon.keyring --import-keyring /etc/ceph/ceph.client.admin.keyring</span><br></pre></td></tr></table></figure>\n<p>4、用规划好的主机名、对应 IP 地址、和 FSID 生成一个Monitor Map，并保存为 <code>/tmp/monmap</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">host_name=`hostname`</span><br><span class=\"line\">sudo monmaptool --create --add $host_name 192.168.226.20  --fsid 932XXXXX-fba7-XXXX-9526-a858c613f468 /tmp/monmap --clobber</span><br></pre></td></tr></table></figure>\n<p>5、在Monitor主机上分别创建数据目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">host_name=`hostname`</span><br><span class=\"line\"><span class=\"meta\">#</span>在admin账户下</span><br><span class=\"line\">sudo mkdir /var/lib/ceph/mon/ceph-$host_name/</span><br></pre></td></tr></table></figure>\n<p>6、用Monitor Map和密钥环组装守护进程所需的初始数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph-mon --mkfs -i $host_name --monmap /tmp/monmap --keyring /tmp/ceph.mon.keyring</span><br></pre></td></tr></table></figure>\n<p>7、建一个空文件 <code>done</code> ，表示监视器已创建、可以启动了</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo touch /var/lib/ceph/mon/ceph-$host_name/done</span><br></pre></td></tr></table></figure>\n<p>8、启动Monitor</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>sudo ceph-mon -f --cluster ceph --id $host_name &amp;</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service</span><br><span class=\"line\">sudo systemctl start ceph-mon@$host_name</span><br><span class=\"line\">sudo systemctl enable ceph-mon@$host_name</span><br></pre></td></tr></table></figure>\n<p>9、确认下集群在运行</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph -s</span><br></pre></td></tr></table></figure>\n<p>事例：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cluster:</span><br><span class=\"line\">  id:     932XXXXX-fba7-XXXX-9526-a858c613f468</span><br><span class=\"line\">  health: HEALTH_OK</span><br><span class=\"line\"> </span><br><span class=\"line\">services:</span><br><span class=\"line\">  mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3</span><br><span class=\"line\">  mgr: no daemons active</span><br><span class=\"line\">  osd: 0 osds: 0 up, 0 in</span><br><span class=\"line\"> </span><br><span class=\"line\">data:</span><br><span class=\"line\">  pools:   0 pools, 0 pgs</span><br><span class=\"line\">  objects: 0 objects, 0B</span><br><span class=\"line\">  usage:   0B used, 0B / 0B avail</span><br><span class=\"line\">  pgs:</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-1-2-从mon节点-192-168-226-22-amp-192-168-226-96\"><a href=\"#3-1-2-从mon节点-192-168-226-22-amp-192-168-226-96\" class=\"headerlink\" title=\"3.1.2 从mon节点 (192.168.226.22 &amp; 192.168.226.96)\"></a>3.1.2 从mon节点 (192.168.226.22 &amp; 192.168.226.96)</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">host_name=`hostname`</span><br><span class=\"line\">sudo ceph mon getmap -o /tmp/monmap</span><br><span class=\"line\">sudo rm -rf /var/lib/ceph/mon/ceph-$host_name</span><br><span class=\"line\">sudo ceph-mon -i $host_name --mkfs --monmap /tmp/monmap</span><br><span class=\"line\">sudo chown -R ceph:ceph /var/lib/ceph/mon/ceph-$host_name/</span><br><span class=\"line\"><span class=\"meta\">#</span>nohup ceph-mon -f --cluster ceph --id $host_name --setuser ceph --setgroup ceph &amp;</span><br><span class=\"line\"><span class=\"meta\">#</span>ceph-mon -f --cluster ceph --id $host_name &amp;</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-mon@.service /usr/lib/systemd/system/ceph-mon@$host_name.service</span><br><span class=\"line\">sudo systemctl start ceph-mon@$host_name</span><br><span class=\"line\">sudo systemctl enable ceph-mon@$host_name</span><br></pre></td></tr></table></figure>\n<h3 id=\"3-2-创建ceph-mgr\"><a href=\"#3-2-创建ceph-mgr\" class=\"headerlink\" title=\"3.2 创建ceph-mgr\"></a>3.2 创建ceph-mgr</h3><h4 id=\"3-2-1-创建用户-openstack-用于-MGR-监控\"><a href=\"#3-2-1-创建用户-openstack-用于-MGR-监控\" class=\"headerlink\" title=\"3.2.1 创建用户 openstack 用于 MGR 监控\"></a>3.2.1 创建用户 openstack 用于 MGR 监控</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph auth get-or-create mgr.openstack mon 'allow *' osd 'allow *' mds 'allow *'</span><br><span class=\"line\">输出：</span><br><span class=\"line\">[mgr.openstack]</span><br><span class=\"line\">        key = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxugvXkLfgauLA==</span><br></pre></td></tr></table></figure>\n<p>需要将之前创建的用户密码存放至对应位置</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mkdir /var/lib/ceph/mgr/ceph-openstack</span><br><span class=\"line\">ceph auth get mgr.openstack -o  /var/lib/ceph/mgr/ceph-openstack/keyring</span><br><span class=\"line\">exported keyring for mgr.openstack</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-2-2-启动mgr\"><a href=\"#3-2-2-启动mgr\" class=\"headerlink\" title=\"3.2.2 启动mgr\"></a>3.2.2 启动mgr</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph-mgr -i openstack</span><br></pre></td></tr></table></figure>\n<p>监控状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span>ceph -s</span><br><span class=\"line\">  cluster:</span><br><span class=\"line\">    id:     932e88a6-fba7-45a9-9526-a858c613f468</span><br><span class=\"line\">    health: HEALTH_OK</span><br><span class=\"line\"> </span><br><span class=\"line\">  services:</span><br><span class=\"line\">    mon: 3 daemons, quorum ceph-1,ceph-2,ceph-3</span><br><span class=\"line\">    mgr: openstack(active)</span><br><span class=\"line\">    mds: cephfs-1/1/1 up  &#123;0=2=up:active&#125;, 2 up:standby</span><br><span class=\"line\">    osd: 3 osds: 3 up, 3 in</span><br><span class=\"line\"> </span><br><span class=\"line\">  data:</span><br><span class=\"line\">    pools:   2 pools, 256 pgs</span><br><span class=\"line\">    objects: 21 objects, 3.04KiB</span><br><span class=\"line\">    usage:   3.32GiB used, 1.17TiB / 1.17TiB avail</span><br><span class=\"line\">    pgs:     256 active+clean</span><br></pre></td></tr></table></figure>\n<p>当 mgr 服务被激活之后, service 中 mgr 会显示 mgr-$name(active)<br>data 部分信息将变得可用</p>\n<h3 id=\"3-3-手动搭建osd集群-三台机器上做相同的操作，注意osd-id的变化\"><a href=\"#3-3-手动搭建osd集群-三台机器上做相同的操作，注意osd-id的变化\" class=\"headerlink\" title=\"3.3 手动搭建osd集群(三台机器上做相同的操作，注意osd_id的变化)\"></a>3.3 手动搭建osd集群(三台机器上做相同的操作，注意osd_id的变化)</h3><p>添加一个新osd，<code>id</code>可以省略，ceph会自动使用最小可用整数，第一个osd从0开始</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph osd create &#123;id&#125;</span><br><span class=\"line\">ceph osd create</span><br><span class=\"line\">0</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3-1-初始化osd目录\"><a href=\"#3-3-1-初始化osd目录\" class=\"headerlink\" title=\"3.3.1 初始化osd目录\"></a>3.3.1 初始化osd目录</h4><p>创建osd.0目录，目录名格式<code>{cluster-name}-{id}</code></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>mkdir /var/lib/ceph/osd/&#123;cluster-name&#125;-&#123;id&#125;</span><br><span class=\"line\">sudo mkdir /var/lib/ceph/osd/ceph-0</span><br></pre></td></tr></table></figure>\n<p>挂载osd.0的数据盘/dev/sdb2</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkfs.xfs /dev/sdb2</span><br><span class=\"line\">sudo mount /dev/sdb2 /var/lib/ceph/osd/ceph-0</span><br></pre></td></tr></table></figure>\n<p>初始化osd数据目录</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> sudo ceph-osd -i &#123;id&#125; --mkfs --mkkey</span><br><span class=\"line\">sudo ceph-osd -i 0 --mkfs --mkkey</span><br><span class=\"line\"><span class=\"meta\">#</span>--mkkey要求osd数据目录为空</span><br><span class=\"line\"><span class=\"meta\">#</span>这会创建osd.0的keyring /var/lib/ceph/osd/ceph-0/keyring</span><br></pre></td></tr></table></figure>\n<p>初始化后，默认使用普通文件/var/lib/ceph/osd/ceph-3/journal作为osd.0的journal分区，普通文件作为journal分区性能不高，若只是测试环境，可以跳过更改journal分区这一步骤</p>\n<h4 id=\"3-3-2-创建journal\"><a href=\"#3-3-2-创建journal\" class=\"headerlink\" title=\"3.3.2 创建journal\"></a>3.3.2 创建journal</h4><p>生成journal分区，一般选ssd盘作为journal分区，这里使用ssd的/dev/sdb1分区作为journal</p>\n<p>使用fdisk工分出磁盘/dev/sdb1,</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>清除磁盘所有分区(重新添加时需要)</span><br><span class=\"line\"><span class=\"meta\">#</span>sgdisk --zap-all --clear --mbrtogpt /dev/sdb</span><br><span class=\"line\"><span class=\"meta\">#</span>生成分区/dev/sdb1的uuid</span><br><span class=\"line\"><span class=\"meta\">#</span>uuidgen</span><br><span class=\"line\"><span class=\"meta\">#</span>b3897364-8807-48eb-9905-e2c8400d0cd4</span><br><span class=\"line\"><span class=\"meta\">#</span>创建分区</span><br><span class=\"line\"><span class=\"meta\">#</span>1:0:+100G 表示创建第一个分区，100G大小</span><br><span class=\"line\"><span class=\"meta\">#</span>sudo sgdisk --new=1:0:+100G --change-name=1:'ceph journal' --partition-guid=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --typecode=1:b3897364-8807-48eb-9905-e2c8400d0cd4 --mbrtogpt -- /dev/vdf</span><br><span class=\"line\"><span class=\"meta\">#</span>格式化</span><br><span class=\"line\">sudo mkfs.xfs /dev/sdb1</span><br><span class=\"line\">sudo rm -f /var/lib/ceph/osd/ceph-4/journal </span><br><span class=\"line\"><span class=\"meta\">#</span>查看分区对应的partuuid， 找出/dev/sdb1对应的partuuid</span><br><span class=\"line\">sudo blkid</span><br><span class=\"line\">sudo ln -s /dev/disk/by-partuuid/b3897364-8807-48eb-9905-e2c8400d0cd4 /var/lib/ceph/osd/ceph-0/journal</span><br><span class=\"line\"></span><br><span class=\"line\">sudo chown ceph:ceph -R /var/lib/ceph/osd/ceph-0</span><br><span class=\"line\">sudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal</span><br><span class=\"line\"><span class=\"meta\">#</span>初始化新的journal</span><br><span class=\"line\">sudo ceph-osd --mkjournal -i 0</span><br><span class=\"line\">sudo chown ceph:ceph /var/lib/ceph/osd/ceph-0/journal</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3-3-注册osd-id-，id为osd编号，默认从0开始\"><a href=\"#3-3-3-注册osd-id-，id为osd编号，默认从0开始\" class=\"headerlink\" title=\"3.3.3 注册osd.{id}，id为osd编号，默认从0开始\"></a>3.3.3 注册osd.{id}，id为osd编号，默认从0开始</h4><figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span> sudo ceph auth add osd.&#123;id&#125; osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-&#123;id&#125;/keyring</span><br><span class=\"line\">sudo ceph auth add osd.0 osd 'allow *' mon 'allow profile osd' -i /var/lib/ceph/osd/ceph-0/keyring</span><br><span class=\"line\"><span class=\"meta\">#</span>ceph auth list 中出现osd.0</span><br></pre></td></tr></table></figure>\n<h4 id=\"3-3-4-加入crush-map\"><a href=\"#3-3-4-加入crush-map\" class=\"headerlink\" title=\"3.3.4 加入crush map\"></a>3.3.4 加入crush map</h4><p>这是m1上新创建的第一个osd，CRUSH map中还没有m1节点，因此首先要把m1节点加入CRUSH map，同理，m2/m3节点也需要加入CRUSH map</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph osd crush add-bucket &#123;hostname&#125; host</span><br><span class=\"line\">sudo ceph osd crush add-bucket `hostname` host</span><br></pre></td></tr></table></figure>\n<p>然后把三个节点移动到默认的root <code>default</code>下面</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo ceph osd crush move `hostname` root=default</span><br></pre></td></tr></table></figure>\n<p>添加osd.0到CRUSH map中的m1节点下面，加入后，osd.0就能够接收数据</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph osd crush add osd.&#123;id&#125; 0.4 root=sata rack=sata-rack01 host=sata-node5</span><br><span class=\"line\">sudo ceph osd crush add osd.4 1.7 root=default host=`hostname`</span><br><span class=\"line\"><span class=\"meta\">#</span>0.4为此osd在CRUSH map中的权重值，它表示数据落在此osd上的比重，是一个相对值，一般按照1T磁盘比重值为1来计算，这里的osd数据盘1.7，所以值为1.7</span><br></pre></td></tr></table></figure>\n<p>此时osd.0状态是<code>down</code>且<code>in</code>，<code>in</code>表示此osd位于CRUSH map，已经准备好接受数据，<code>down</code>表示osd进程运行异常，因为我们还没有启动osd.0进程</p>\n<h4 id=\"3-3-5-启动ceph-osd进程\"><a href=\"#3-3-5-启动ceph-osd进程\" class=\"headerlink\" title=\"3.3.5 启动ceph-osd进程\"></a>3.3.5 启动ceph-osd进程</h4><p>需要向systemctl传递osd的<code>id</code>以启动指定的osd进程，如下，我们准备启动osd.0进程</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>systemctl start ceph-osd@&#123;id&#125;  id表示osd编号，从数字0开始</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-osd@.service /usr/lib/systemd/system/ceph-osd@0.service</span><br><span class=\"line\">sudo systemctl start ceph-osd@0</span><br><span class=\"line\">sudo systemctl enable ceph-osd@0</span><br><span class=\"line\"><span class=\"meta\">#</span>sudo ceph-osd -i 0</span><br></pre></td></tr></table></figure>\n<p>上面就是添加osd.0的步骤，然后可以接着在其他<code>hostname</code>节点上添加osd.{1,2}，添加了这3个osd后，可以查看集群状态 ceph -s。</p>\n<h3 id=\"3-4-搭建MDS\"><a href=\"#3-4-搭建MDS\" class=\"headerlink\" title=\"3.4 搭建MDS\"></a>3.4 搭建MDS</h3><p>创建目录：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir /var/lib/ceph/mds/ceph-`hostname`</span><br><span class=\"line\">sudo chown ceph:ceph -R /var/lib/ceph/mds/ceph-`hostname`</span><br></pre></td></tr></table></figure>\n<p>在ceph.conf中添加如下信息：</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[mds.&#123;id&#125;]</span><br><span class=\"line\">host = &#123;id&#125;</span><br><span class=\"line\">例如：</span><br><span class=\"line\">[mds.0]</span><br><span class=\"line\">host = 0</span><br></pre></td></tr></table></figure>\n<p>启动mds</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span>ceph-mds --cluster &#123;cluster-name&#125; -i &#123;id&#125; -m &#123;mon-hostname&#125;:&#123;mon-port&#125; [-f]</span><br><span class=\"line\">sudo cp /usr/lib/systemd/system/ceph-mds@.service /usr/lib/systemd/system/ceph-mds@`hostname`.service </span><br><span class=\"line\">sudo systemctl start ceph-mds@`hostname`</span><br><span class=\"line\">sudo systemctl enable ceph-mds@`hostname`</span><br><span class=\"line\"><span class=\"meta\">#</span>ceph-mds --cluster ceph -i 0 -m e15p13447.ew9:6789</span><br></pre></td></tr></table></figure>\n<p>查看mds状态</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ceph mds stat</span><br><span class=\"line\">cephfs-1/1/1 up  &#123;0=1=up:active&#125;, 2 up:standby</span><br></pre></td></tr></table></figure>\n<p>至此ceph集群搭建完成。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjoimgt070003ppygtst2of76","category_id":"cjoimgt0e0004ppyg892r6car","_id":"cjoimgt0i0007ppygyjlzdhch"}],"PostTag":[{"post_id":"cjoimgt070003ppygtst2of76","tag_id":"cjoimgt0f0005ppyglnjq5lum","_id":"cjoimgt0h0006ppygn08b1hsn"}],"Tag":[{"name":"ceph","_id":"cjoimgt0f0005ppyglnjq5lum"}]}}